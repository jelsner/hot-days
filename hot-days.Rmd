---
title: "Hot Days in Tallahassee"
author: "James Elsner"
date: "5/16/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

## More hots: Upward trends in the occurrence of extremely hot days and nights in Tallahassee, Florida, USA

About the climate in Tallahassee.
http://weatherspark.com/history/31772/2013/Tallahassee-Florida-United-States
http://www.fao.org/geonetwork/srv/en/main.home

WSO weather station site: current location (since 1996) 30.39306°, -84.35333° Downtown weather station site location 30.43333°, -84.28333° Compare with Albany GA?

Raster map. Close up.
```{r}
Sites.df <- data.frame(Name = c("Regional Airport", "Downtown", 
                                "Dale Mabry Field", "Municipal Airport"), 
                       Latitude = c(30.39306, 30.43333, 30.44, 30.38),
                       Longitude = c(-84.35333, -84.28333, -84.338, -84.37))
```

```{r, eval=FALSE}
library(ggmap)

register_google(key = "")
getOption("ggmap")

geocode("Tallahassee Airport")

g_map <- get_googlemap(center = c(lon = -84.325, lat = 30.41),
                    zoom = 13, scale = 2,
                    maptype = 'satellite',
                    color = 'color')

cds <- attr(g_map, "bb")

bbx <- st_sfc(st_polygon(list(matrix(c(cds$ll.lon, cds$ur.lat,
                     cds$ur.lon, cds$ur.lat,
                     cds$ur.lon, cds$ll.lat,
                     cds$ll.lon, cds$ll.lat,
                     cds$ll.lon, cds$ur.lat), ncol = 2, byrow = TRUE))),
              crs = 4326)

p <- ggmap(g_map)

mainMap <- p + 
    geom_point(aes(x = Longitude, y = Latitude), 
               data = Sites.df, size = 2, col = c("orange", "red", "orange", "orange")) +
    geom_label(aes(x = Longitude, y = Latitude, label = Name), 
             data = Sites.df,
             nudge_y = -.0025,
             nudge_x = .005) +
    theme_void() +
    theme(legend.position = "none")
```

Create a map with an inset showing Florida and Leon County.
```{r}
library(sf)
library(dplyr)

library(tmap)
library(USAboundaries)

FL.sf <- us_states(states = "Florida")
FL.sf$name <- "            Florida"
ALGA.sf <- us_states(states = c("Alabama", "Georgia"))

Leon.sf <- us_counties(states = "FL") %>%
  filter(name == "Leon")

inset.tm <- 
    tm_shape(FL.sf, projection = "laea_NA") +
       tm_polygons(col = "white") +
       tm_text(text = "name", size = 1) +
    tm_shape(ALGA.sf) +
       tm_polygons(col = "gray") +
    tm_shape(Leon.sf) +
       tm_borders() +
#    tm_shape(bbx) +
 #      tm_polygons(col = "black") +
    tm_compass(type = "arrow", position = c("left", "bottom")) +
    tm_scale_bar(position = c("left", "bottom"), size = .55) +
    tm_style("natural")

library(grid)

#mainMap
#print(inset.tm, vp = viewport(.75, .25, width = .7, height = .4))
inset.tm
```
###Figure: Satellite image showing the locations of the sites where daily temperature records were taken in the city of Tallahassee. Inset: Leon County, Florida. The black square inside the county is the area of the background satellite image.

Get the data. Ordered online from 
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail
 Elev: 55 ft. Lat: 30.3931° N Lon: -84.3533° W

TALLAHASSEE REGIONAL AIRPORT, FL US (Station ID: GHCND:USW00093805)
TALLAHASSEE, FL US (Station ID: GHCND:USC00088754)

Sofia Bulgaria
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:BUM00015614/detail

https://docs.opendata.aws/noaa-ghcn-pds/readme.html

### Hot days and nights

Get data.
```{r}
library(lubridate)

TLH.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), 
             Month = month(Date), 
             Day = day(Date),
             doy = yday(Date)) %>%
      dplyr::select(Date, Year, Month, Day, doy, TMAX, TMIN, PRCP)
```

* TMAX: Daily maximum temperature, 
* TMIN: Daily minimum temperature, 
* PRCP: Daily total precipitation, 
* WDF1: Wind direction of fastest one-minute wind, 
* WSF1: Wind speed of fastest one-minute wind

Add temperatures for July 8, 2005 from Weather Underground. Use previous day min for October 8, 2002. These do not influence the results.
```{r}
TLH.df$Date[is.na(TLH.df$TMAX)]
TLH.df$Date[is.na(TLH.df$TMIN)]

TLH.df$TMAX[TLH.df$Date == "2005-07-08"] <- 96
TLH.df$TMIN[TLH.df$Date == "2005-07-08"] <- 71
TLH.df$TMIN[TLH.df$Date == "2002-10-08"] <- TLH.df$TMIN[TLH.df$Date == "2002-10-07"]
```

When were the last hot days? Hottest days. Hot days since 2009. Note: At least two hot days in 2019.
```{r}
TLH.df %>% 
  filter(TMAX >= 100) %>%
  arrange(desc(Date)) %>%
  head(n = 20)

TLH.df %>%
  arrange(desc(TMAX)) %>%
  head(n = 20)

TLH.df %>%
  filter(Year >= 2009 & TMAX >= 100) %>%
  dplyr::select(Date) %>%
  pull()
```

Histogram of daily high temperature.
```{r}
FreqByT <- TLH.df %>%
#  filter(Month >= 5 & Month <= 9) %>%
#    filter(Year < 1980) %>%
  group_by(TMAX) %>%
  summarize(nH = n())
FreqByT2 <-FreqByT %>%
  filter(TMAX >= 100)

p1 <- ggplot(FreqByT, aes(x = TMAX, y = nH)) +
  geom_bar(stat = 'identity', col = 'white', fill = "gray70") +
  geom_bar(data = FreqByT2, stat = 'identity', fill = "orange") +
  scale_x_continuous(limits = c(5, 106),
                     breaks = seq(40, 100, 10),
                     labels = paste0(seq(40, 100, 10), "°")) +
  scale_y_continuous(position = "right", limits = c(0, 1600)) +
  ylab("Number of Days") +  xlab("                        Daily High Temperature (F)") +
#  ggtitle(label = "Frequency of Daily High Temperatures",
#          subtitle = "Tallahassee, FL, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank())

FreqByT <- TLH.df %>%
#    filter(Month >= 5 & Month <= 9) %>%
#  filter(Year < 1980) %>%
  group_by(TMIN) %>%
  summarize(nH = n())
FreqByT2 <-FreqByT %>%
  filter(TMIN >= 77)

p2 <- ggplot(FreqByT, aes(x = TMIN, y = nH)) +
  geom_bar(stat = 'identity', col = 'white', fill = "gray70") +
  geom_bar(data = FreqByT2, stat = 'identity', fill = "orange") +
  scale_x_continuous(limits = c(5, 106),
                     breaks = seq(20, 80, 10),
                     labels = paste0(seq(20, 80, 10), "°")) +
  scale_y_continuous(position = "right", limits = c(0, 1600)) +
  ylab("Number of Days") + xlab("Daily Low Temperature (F)                     ") +
#  ggtitle(label = "Frequency of Daily Low Temperatures",
#          subtitle = "Tallahassee, FL, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank()) 

library(ggpubr)

ggarrange(p1, p2, 
          nrow = 2, 
#          labels = c("Daily High Temperature", 
#                    "Daily Low Temperature"),
          font.label = list(face = "plain", size = 11))
```
###Figure: The number of days by high temperature (top) and by low temperature (bottom).

How many hot days/nights? Median date. Seasonal variability.
```{r}
TLH.df %>%
  summarize(nD = n(),
            N100 = sum(TMAX >= 100),
            N77 = sum(TMIN >= 77),
            Q99Max = quantile(TMAX, probs = .99),
            Q99Min = quantile(TMIN, probs = .99),
            qtle100 = 1 - N100/nD,
            qtle77 = 1 - N77/nD)

TLH.df %>%
  filter(TMAX >= 98) %>%
  group_by(TMAX) %>%
  summarize(nD = n())

TLH.df %>%
  filter(TMIN >= 75) %>%
  group_by(TMIN) %>%
  summarize(nD = n())
```

The 99.555th percentile of the distribution of daily high temperatures in the observations. 4 days in 1000. The 99.4368th percentile of the distribution of daily low temperatures.

Monthly counts.
```{r}
library(xtable)
TLH.df %>%
  group_by(Month) %>%
  summarize(N100 = sum(TMAX >= 100, na.rm = TRUE),
            N77 = sum(TMIN >= 77, na.rm = TRUE)) %>%
  filter(Month %in% 5:10) %>%
  mutate(MonthName = month.name[Month]) %>%
  dplyr::select(MonthName, N100, N77) %>%
  xtable()
  
```
###Table: Monthly counts.

Seasonality. 
```{r}
TLH.df %>%
  filter(TMIN >= 77) %>%
  arrange(desc(doy)) %>%
  head

TLH.df %>%
  filter(TMAX >= 100) %>%
  summarize(medianDate = median(doy))

# 182: July 1st
TLH.df %>%
  filter(TMIN >= 77) %>%
  summarize(medianDate = median(doy))
# 216: August 4th

library(reshape2)

DOY <- TLH.df %>%
  group_by(doy) %>%
  summarize("Daytime High Reached 100° F" = sum(TMAX >= 100, na.rm = TRUE),
            "Nighttime Low Remained Above 77° F" = sum(TMIN >= 77, na.rm = TRUE)) %>%
  filter(doy %in% 139:285) %>%
  melt(id.vars = "doy")

ggplot(DOY, aes(x = doy, y = value)) +
  geom_bar(stat = 'identity', col = "white", fill = "orange") +
  scale_x_continuous(position = "bottom", 
                     breaks = c(152, 166, 182, 196, 213, 227, 244, 259, 274),
                     labels = c("June 1", "June 15", 
                                "July 1", "July 15", 
                                "August 1", "August 15",
                                "September 1", "September 15",
                                "October 1")) +
  scale_y_continuous(position = "left") +
  facet_wrap(~ variable, nrow = 2, strip.position = "top") +
  ylab("Number of Times") + xlab("") +
#  ggtitle(label = "Number of Extremely Hot Days & Nights By Day of Year",
#          subtitle = "Tallahassee, Florida, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text.x = element_text(size = 11),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
#  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) 
```
###Figure: Number of times by day of the year the daily high reached 100F (top) and number of times the daily low remained at or above 77F.

Humid season.
```{r}
TLH.df %>%
  filter(Month >= 5 & Month <= 9) %>%
  group_by(doy) %>%
  summarize(nDays = n(),
            pDaysWithRain = sum(PRCP > 0)/nDays) %>%
  ggplot(aes(x = doy, y = pDaysWithRain)) +
  geom_line()

RainDays.df <- TLH.df %>%
  filter(Month >= 5 & Month <= 9) %>%
  filter(PRCP > 0)

  table(RainDays.df$doy)/79

ggplot(RainDays.df, aes(x = doy)) +
  geom_histogram(binwidth = 5, col = "white")
```

Daily records.
```{r}
dailyRecs <- TLH.df %>% 
  group_by(Month, Day) %>%
  summarize(dMaxMax = max(TMAX, na.rm=TRUE),
            dMaxMin = max(TMIN, na.rm=TRUE),
            dMaxMaxY = Year[which.max(TMAX)],
            dMaxMinY = Year[which.max(TMIN)])

dailyRecs %>%
  group_by(dMaxMaxY) %>%
  summarize(count = length(dMaxMaxY)) %>%
ggplot(aes(x = dMaxMaxY, y = count)) +
  geom_bar(stat = 'identity') +
  ylab("Number of dates having the daily record high maximum")

dailyRecs %>%
  group_by(dMaxMinY) %>%
  summarize(count = length(dMaxMinY)) %>%
ggplot(aes(x = dMaxMinY, y = count)) +
  geom_bar(stat = 'identity') +
  ylab("Number of dates having the daily record high minimum")
```

Annual time series of extreme counts.
```{r}
library(MASS)
TLH.df %>% 
  group_by(Year) %>%
  summarize("High Temperature At Or Above 100°"  = sum(TMAX >= 100, na.rm = TRUE),
            "Low Temperature At Or Above 77°" = sum(TMIN >= 77, na.rm = TRUE)) %>%
  melt(id.vars = "Year") %>%
ggplot(aes(x = Year, y = value)) + 
  stat_smooth(method = "glm.nb",
              formula = y ~ x, 
              se = FALSE,
              col = "orange") +
  geom_bar(stat = 'identity', col = "white", fill = "gray70") + 
#  scale_fill_continuous(low = 'orange', high = 'red') +
  scale_x_continuous(position = "top", breaks = seq(1940, 2020, by = 10)) +
  scale_y_continuous(limits = c(0, 25), position = "left") +
#  geom_text(aes(label = value), vjust = -.5, size = 2.5) +
  facet_wrap(~ variable, nrow = 2, strip.position = "bottom") +
  ylab("Number of Days") + xlab("") +
#  ggtitle(label = "Number of Extremely Hot Days & Nights",
#          subtitle = "Tallahassee, Florida, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
#        panel.grid.major = element_blank(),
        strip.text.x = element_text(size = 11),
        legend.position = "none") 
 # labs(caption = "Data: Global Historical Climate Network") +
 # theme(plot.caption = element_text(size = 9, color = "grey50")) 
```
### Figure: Time series of the number of extremely hot days and nights.

Arrange years by highest number of extreme days.
```{r}
TLH.df %>% 
  group_by(Year) %>%
  summarize(N100 = sum(TMAX >= 100)) %>%
  arrange(desc(N100))

TLH.df %>% 
  group_by(Year) %>%
  summarize(N77 = sum(TMIN >= 77)) %>%
  arrange(desc(N77))
```

Quantify the trend.
```{r}
Yearly.df <- TLH.df %>% 
  group_by(Year) %>%
  summarize(MaxCount  = sum(TMAX >= 100),
            MinCount = sum(TMIN >= 77))

Yearly.df %>%
  summarize(avgCountMax = mean(MaxCount),
            avgCountMin = mean(MinCount),
            varCountMax = var(MaxCount),
            varCountMin = var(MinCount),
            ratioMax = varCountMax/avgCountMax,
            ratioMin = varCountMin/avgCountMin)

var(Yearly.df$MaxCount)/mean(Yearly.df$MaxCount)
var(Yearly.df$MinCount)/mean(Yearly.df$MinCount)

exp(coef(glm.nb(MaxCount ~ 1, data = Yearly.df)))  # 1.62 =  annual rate of 100+F days
exp(coef(glm.nb(MaxCount ~ Year, data = Yearly.df))) # 1.02% or 2% per year increase in annual rate

exp(coef(glm.nb(MinCount ~ 1, data = Yearly.df))) # 2.05  annual rate of 77+F nights
exp(coef(glm.nb(MinCount ~ Year, data = Yearly.df))) # 1.045 or 4.5% per year increase in annual rate

fitNBMax <- glm.nb(MaxCount ~ Year, data = Yearly.df)
fitPO <- glm(MaxCount ~ Year, data = Yearly.df, family = "poisson")
AIC(fitNBMax); AIC(fitPO)

pchisq(2 * (logLik(fitNBMax) - logLik(fitPO)), df = 1, lower.tail = FALSE)

(exp(summary(fitNBMax)$coefficients[2]) - 1) * 100  # Trend (%/yr)
(exp(summary(fitNBMax)$coefficients[4]) - 1) * 100   # Margin of error (%/yr)

predict(fitNBMax, newdata = data.frame(Year = 1940), type = "response", se = TRUE)
predict(fitNBMax, newdata = data.frame(Year = 2018), type = "response", se = TRUE)
```

For the negative binomial.
```{r}
pnbinom(0, size = 1, mu = .6278)  # probabilty of no hot days when the mean is .6278
(1 - pnbinom(0:4, size = 1, mu = .6278)) * 100 # probability of at least 1, at least 2, ...
(1 - pnbinom(0:4, size = 1, mu = 3.235707)) * 100
```

```{r}
fitNBMin <- glm.nb(MinCount ~ Year, data = Yearly.df)

(exp(summary(fitNBMin)$coefficients[2]) - 1) * 100  # Trend (%/yr)
(exp(summary(fitNBMin)$coefficients[4]) - 1) * 100   # Margin of error (%/yr)

predict(fitNBMin, newdata = data.frame(Year = 1940), type = "response", se = TRUE)
predict(fitNBMin, newdata = data.frame(Year = 2018), type = "response", se = TRUE)

(1 - pnbinom(0:4, size = 1, mu = .22093)) * 100 # probability of at least 1, at least 2, ...
(1 - pnbinom(0:4, size = 1, mu = 6.77268)) * 100
```

### Hot events

Determine hot events (day & night).
```{r}
hotDayEvents <- rle(TLH.df$TMAX >= 100)
hotNightEvents <- rle(TLH.df$TMIN >= 77)

dayEventLength <- hotDayEvents$lengths[hotDayEvents$values]
dayEventNo <- rep(1:length(dayEventLength), dayEventLength)

nightEventLength <- hotNightEvents$lengths[hotNightEvents$values]
nightEventNo <- rep(1:length(nightEventLength), nightEventLength)

dayEvents.df <- TLH.df %>%
  filter(TMAX >= 100) %>%
  mutate(dayEventNo = dayEventNo)

nightEvents.df <- TLH.df %>%
  filter(TMIN >= 77) %>%
  mutate(nightEventNo = nightEventNo)
```

Determine the number of days between successive 100+F days. Add this as another column. Repeat for nights between successive 77+F nights.
```{r}
dayEvents.df <- dayEvents.df %>%
  mutate(daysBetween = Date - lag(Date))

dayEvents.df %>%
  summarize(totalNoEvents = last(dayEventNo),
            maxTimeBetween = max(daysBetween, na.rm = TRUE),
            minTimeBetween = min(daysBetween, na.rm = TRUE),
            medianTimeBetween = median(daysBetween, na.rm = TRUE))

nightEvents.df <- nightEvents.df %>%
  mutate(nightsBetween = Date - lag(Date))

nightEvents.df %>%
  summarize(totalNoEvents = last(nightEventNo),
            maxTimeBetween = max(nightsBetween, na.rm = TRUE),
            minTimeBetween = min(nightsBetween, na.rm = TRUE),
            medianTimeBetween = median(nightsBetween, na.rm = TRUE))
```

Length and intensity of events.
```{r}
LIdayEvents.df <- dayEvents.df %>%
  group_by(dayEventNo) %>%
  summarize(eventLength = n(),
            avgEventT = mean(TMAX),
            maxEventT = max(TMAX),
            whenMaxEvT = which.max(TMAX),
            Year = Year[1])
LInightEvents.df <- nightEvents.df %>%
  group_by(nightEventNo) %>%
  summarize(eventLength = n(),
            avgEventT = mean(TMIN),
            maxEventT = max(TMIN),
            whenMaxEvT = which.max(TMIN),
            Year = Year[1])

LIdayEvents.df %>%
  summarize(avgEventLength = mean(eventLength),
            medEventLength = median(eventLength),
            maxEventLength = max(eventLength),
            whenMaxEventLength = which.max(eventLength))
dayEvents.df$Date[dayEvents.df$dayEventNo == 39]

LInightEvents.df %>%
  summarize(avgEventLength = mean(eventLength),
            medEventLength = median(eventLength),
            maxEventLength = max(eventLength),
            whenMaxEventLength = which.max(eventLength))
nightEvents.df$Date[nightEvents.df$nightEventNo == 100]

# empirical chance of another hot day 
sum(LIdayEvents.df$eventLength > 1)/length(LIdayEvents.df$eventLength) # 41.4%
sum(LInightEvents.df$eventLength > 1)/length(LInightEvents.df$eventLength) # 23.3%

cor(LIdayEvents.df$eventLength, LIdayEvents.df$maxEventT, method = "s") # .55
cor(LInightEvents.df$eventLength, LInightEvents.df$maxEventT, method = "s") # .54

```

Relationships between event length and maximum event temperature.
```{r}
library(lme4)

summary(lm(eventLength ~ Year, data = LIdayEvents.df))
summary(lm(maxEventT ~ eventLength, data = LIdayEvents.df))

summary(lm(eventLength ~ Year, data = LInightEvents.df))
summary(lm(maxEventT ~ eventLength, data = LInightEvents.df))
```

```{r}
LIdayEvents2.df <- LIdayEvents.df %>%
  group_by(Year) %>%
  summarize(count = n(),
            avgEL = mean(eventLength))
LInightEvents2.df <- LInightEvents.df %>%
  group_by(Year) %>%
  summarize(count = n(),
            avgEL = mean(eventLength))

AllYears <- data.frame(Year = 1940:2018)

LIdayEvents2.df <- merge(AllYears, LIdayEvents2.df, by = "Year", all.x = TRUE)
LIdayEvents2.df$count[is.na(LIdayEvents2.df$count)] <- 0

LInightEvents2.df <- merge(AllYears, LInightEvents2.df, by = "Year", all.x = TRUE)
LInightEvents2.df$count[is.na(LInightEvents2.df$count)] <- 0

var(LIdayEvents2.df$count)/mean(LIdayEvents2.df$count) # 2.46
var(LInightEvents2.df$count)/mean(LInightEvents2.df$count) # 3.91
```

Plot trends in frequency and duration.
```{r}
p1 <- ggplot(data = LIdayEvents2.df, aes(x = Year, y = count)) +
   geom_point(col = "gray70") +
#   stat_smooth(method = "glm.nb",
#              formula = y ~ x, 
#              data = LIdayEvents2.df, se = TRUE) +
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2), position = "left") +
  ylab("Number") + xlab("") +
  theme_minimal() +
    ggtitle("Frequency of daytime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 11))

p2 <- ggplot(data = LIdayEvents2.df, aes(x = Year, y = avgEL)) +
   geom_bar(stat = "identity", fill = "gray70", color = "white") +
#  stat_smooth(method = "glm",
#               method.args = list(family = "Gamma"),
#               formula = y ~ x, 
#               se = TRUE)
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(position = "left", breaks = seq(1, 8, 1)) +
  ylab("Average (days)") + xlab("") +
  theme_minimal() +
    ggtitle("Length of daytime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 11)) 

p3 <- ggplot(data = LInightEvents2.df, aes(x = Year, y = count)) +
  geom_point(col = "gray70") +
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(limits = c(0, 14), breaks = seq(0, 14, 2), position = "left") +
  ylab("Number") + xlab("") +
  theme_minimal() +
    ggtitle("Frequency of nighttime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 11)) 

p4 <- ggplot(data = LInightEvents2.df, aes(x = Year, y = avgEL)) +
   geom_bar(stat = "identity", fill = "gray70", color = "white") +
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(position = "left", breaks = seq(1, 8, 1)) +
  ylab("Average (nights)") + xlab("") +
  theme_minimal() +
    ggtitle("Length of nighttime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 11))

ggarrange(p1, p3, p2, p4, ncol = 2, nrow = 2)
```
###Figure: Frequency and duration of hot daytime and nighttime events.

###Hot day preceded or followed by a hot night

Hot days and nights together.
```{r}
TLH.df %>%
  filter(TMAX >= 100 & TMIN >= 77 | 
 #        TMAX >= 100 & lag(TMIN >= 77) |
         TMAX >= 100 & lead(TMIN >= 77)) 

TLH.df %>%
  filter(TMAX >= 100 & TMIN >= 77 | 
         TMAX >= 100 & lead(TMIN >= 77)) %>%
  group_by(Month) %>%
  summarize(nE = n())
```

1940-49 0
1950-59 3
1960-69 0
1970-79 0
1980-89 6
1990-99 4
2000-09 9
2010-18 11

### Shifting extremes

Trends in TMAX and TMIN.
```{r}
mean(TLH.df$TMAX)
mean(TLH.df$TMIN)

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

TLH.df %>%
#  filter(Month >= 5 & Month <= 8) %>%
#  filter(doy >= 145 & doy <= 241) %>%  # Day
  filter(doy >= 146 & doy <= 282) %>%  # Night
  group_by(Year < 1980) %>%
  summarize(avgTMAX = mean(TMAX),
            avgTMIN = mean(TMIN),
            medTMAX = median(TMAX),
            medTMIN = median(TMIN),
            modeTMAX = Mode(TMAX),
            modeTMIN = Mode(TMIN),
            nDays = n(),
            modalFreqMax = sum(TMAX == modeTMAX)/nDays,
            modalFreqMin = sum(TMIN == modeTMIN)/nDays)

TLH.df %>%
#  filter(Month >= 5 & Month <= 8) %>%
#  filter(doy >= 145 & doy <= 241) %>%  # Day
#  filter(doy >= 146 & doy <= 282) %>%  # Night
  group_by(Year) %>%
  summarize(avgTMAX = mean(TMAX),
            avgTMIN = mean(TMIN),
            modeTMAX = Mode(TMAX),
            modeTMIN = Mode(TMIN)) %>%
  ggplot(aes(x = Year, y = modeTMIN)) +
  geom_point() +
  geom_smooth(method = lm)
```

Upward trends in TMAX and TMIN. Most pronounced for TMAX.

Compare with the number of 90F days. The upward trend starts at 95F. No changes in temps lower than that. This contrasts with the standard model where we expect upward trends in all temperatures above the average temperature.
```{r}
TLH.df %>% 
#  filter(Month >= 5 & Month <= 9) %>%
  group_by(Year) %>% 
  summarize(n90 = sum(TMAX == 84)) %>% 
#  summarize(mT = mean(TMAX)) %>%
  ggplot(aes(Year, n90)) + 
  geom_point() +
  geom_smooth(method = lm)
```

Temperature distributions by epoch for days defined by the hot day/night seasons.
```{r}
DayFreqByT <- TLH.df %>%
  filter(doy >= 145 & doy <= 241) %>%
  mutate(Epoch = Year < 1980,
         When = "Hot Season Daytime Highs",
         Temp = TMAX) %>%
  dplyr::select(Temp, Epoch, When)

NightFreqByT <- TLH.df %>%
  filter(doy >= 146 & doy <= 282) %>%  # Night
  mutate(Epoch = Year <= 1980,
         When = "Hot Season Nighttime Lows",
         Temp = TMIN) %>%
  dplyr::select(Temp, Epoch, When)

library(forcats)

FreqByT <- rbind(NightFreqByT, DayFreqByT) %>%
  mutate(EpochF = factor(Epoch, 
                         levels = c("FALSE", "TRUE"))) %>%
  mutate(EpochF = fct_reorder(EpochF, Temp),
         EpochF = fct_reorder(EpochF, When))

ggplot(FreqByT, aes(x = Temp, color = EpochF)) +
  geom_density(bw = 1, size = 1) +
  geom_hline(yintercept = 0, size = 1, col = "gray70") +
  scale_x_continuous(breaks = seq(40, 100, 10),
                     labels = paste0(seq(40, 100, 10), "°")) +
#  scale_color_manual(labels = c("1980-2018", "1940-1979"), values = c("red", "orange")) +
  scale_color_manual(labels = c("1940-1979", "1980-2018"), values = c("orange", "red")) +
  facet_wrap(~ When, nrow = 2) +
  xlab("Temperature (F)") +  ylab("Relative Frequency") +
  labs(color = "") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        legend.position = "top")
```

### Analysis of temperatures when data are available at both sites

```{r}
ALL.df <- read.csv(file = 'TLH_SOD1892.csv',
                   stringsAsFactors = FALSE,
                   header = TRUE) %>%
        mutate(Date = as.Date(DATE))

ALL.df %>%
  filter(STATION == "USC00088754") %>%
  summarize(start = first(Date),
            end = last(Date))

duplicateRows <- duplicated(ALL.df$Date)
duplicateDates <- ALL.df$Date[duplicateRows]

df1 <- ALL.df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USC00088754")

df2 <- ALL.df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USW00093805") %>%
  dplyr::select(STATION2 = STATION, TMAX2 = TMAX, TMIN2 = TMIN, PRCP2 = PRCP)

OVR.df <- cbind(df1, df2)
```

TMAX2/TMIN2: Airport, TMAX/TMIN: Downtown
```{r}
OVR.df %>%
  summarize(avgTMAX = mean(TMAX, na.rm = TRUE),
            avgTMAX2 = mean(TMAX2, na.rm = TRUE),
            avgTMIN = mean(TMIN, na.rm = TRUE),
            avgTMIN2 = mean(TMIN2, na.rm = TRUE))

OVR.df %>%
  filter(TMAX >= 100) %>%
  summarize(avgTMAX = mean(TMAX, na.rm = TRUE),
            avgTMAX2 = mean(TMAX2, na.rm = TRUE),
            avgTMIN = mean(TMIN, na.rm = TRUE),
            avgTMIN2 = mean(TMIN2, na.rm = TRUE))

OVR.df %>%
  filter(TMIN >= 77) %>%
  summarize(avgTMAX = mean(TMAX, na.rm = TRUE),
            avgTMAX2 = mean(TMAX2, na.rm = TRUE),
            avgTMIN = mean(TMIN, na.rm = TRUE),
            avgTMIN2 = mean(TMIN2, na.rm = TRUE))

OVR.df %>%
  summarize(DTN_N100 = sum(TMAX >= 100, na.rm = TRUE),
            TLH_N100 = sum(TMAX2 >= 100, na.rm = TRUE),
            DTN_N77 = sum(TMIN >= 77, na.rm = TRUE),
            TLH_N77 = sum(TMIN2 >= 77, na.rm = TRUE))
          
```

Logistic regression model.
```{r}
lrm0 <- glm(I(TMAX2 >= 100) ~ 1, data = OVR.df, family = "binomial")
lrm1 <- glm(I(TMAX2 >= 100) ~ TMAX, data = OVR.df, family = "binomial")
predict(lrm, newdata = data.frame(TMAX = c(95:103)), type = "response")
AIC(lrm0)
AIC(lrm1)

pred <- predict(lrm1, newdata = data.frame(TMAX = c(95:104)), type = "response") * 100 
data.frame(TMAX = c(95:104), PredProbs = pred) %>%
  xtable()
```

Bayesian logistic regression.
```{r}
library(brms)

OVRhotDays.df <- OVR.df %>%
  filter(TMAX >= 94) %>%
  mutate(TDT = scale(TMAX),
         TI = as.integer(TMAX2 >= 100))

OVRhotNights.df <- OVR.df %>%
  filter(TMIN >= 73) %>%
  mutate(TDT = scale(TMIN),
         TI = as.integer(TMIN2 >= 77))


family <- brms::bernoulli

formula <- TI ~ TMAX
get_prior(formula, data = OVRhotDays.df, family = family)

fit1 <- brm(formula = formula,
            data = OVRhotDays.df,
            family = family,
            prior = c(set_prior("normal(0, 5)", class = "b"),
                     set_prior("student_t(3, 0, 10)", class = "Intercept")),
            seed = 711)

formula <- TI ~ TMIN
get_prior(formula, data = OVRhotNights.df, family = family)

fit2 <- brm(formula = formula,
            data = OVRhotNights.df,
            family = family,
            prior = c(set_prior("normal(0, 5)", class = "b"),
                     set_prior("student_t(3, 0, 10)", class = "Intercept")),
            seed = 713)

summary(fit1)
summary(fit2)

library(tidybayes)
library(modelr)

# initialize out data frame
out1 <- OVRhotDays.df %>%
  data_grid(TMAX = 96:106) %>%
  add_predicted_draws(fit1, n = 1000) %>%
  mutate(pTMAX2 = .prediction) %>%
  group_by(TMAX) %>%
  summarize(nTMAX = n(),
            prob100 = sum(pTMAX2)/nTMAX * 100)

# rbind to the initialized data frame
for(i in 2:100){
  out1 <- OVRhotDays.df %>%
  data_grid(TMAX = 96:106) %>%
  add_predicted_draws(fit1, n = 1000) %>%
  mutate(pTMAX2 = .prediction) %>%
  group_by(TMAX) %>%
  summarize(nTMAX = n(),
            prob100 = sum(pTMAX2)/nTMAX * 100) %>%
    rbind(out1)
}

out1$I <- rep(1:100, each = 11)

( p1 <- ggplot(out1, aes(x = TMAX, y = prob100, group = I)) +
  geom_jitter(alpha = .2, size = .5, width = .1) +
  scale_x_continuous(breaks = 96:106) +
  xlab("High Temperature Downtown (°F)") +
  ylab("Estimated Probability (%) of a Hot Day\n at WSO Tallahassee") +
    ggtitle("A") +
#  ggtitle("Chance WSO Tallahassee Reports a 100+°F Day",
#          subtitle = "Given High Temperatures Downtown") +
  theme_minimal() +
  theme(panel.grid.minor.x = element_blank()) )

# initialize out data frame
out2 <- OVRhotNights.df %>%
  data_grid(TMIN = 74:81) %>%
  add_predicted_draws(fit2, n = 1000) %>%
  mutate(pTMIN2 = .prediction) %>%
  group_by(TMIN) %>%
  summarize(nTMIN = n(),
            prob77 = sum(pTMIN2)/nTMIN * 100)

# rbind to the initialized data frame
for(i in 2:100){
  out2 <- OVRhotNights.df %>%
  data_grid(TMIN = 74:81) %>%
  add_predicted_draws(fit2, n = 1000) %>%
  mutate(pTMIN2 = .prediction) %>%
  group_by(TMIN) %>%
  summarize(nTMIN = n(),
            prob77 = sum(pTMIN2)/nTMIN * 100) %>%
    rbind(out2)
}

out2$I <- rep(1:100, each = 8)
```

Get the data from the downtown site. Filter by days at or above 92F then use the model to predict the temperature at the WSO site. August 31, 1895 TMAX = 2768 is removed. Remove days after the start of the airport record. Do the same for hot minima. The 89 low stands out.
```{r}
DTN1.df <- ALL.df %>%
      filter(STATION == 'USC00088754') %>%
      filter(TMAX >= 92) %>%
      filter(TMAX != 2768) %>%
      filter(Date < as.Date("1940-03-01")) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      dplyr::select(Date, Year, Month, Day, TMAX, TMIN, PRCP) 
table(DTN1.df$TMAX)

sum(DTN1.df$TMAX >= 100)

DTN2.df <- ALL.df %>%
      filter(STATION == 'USC00088754') %>%
      filter(TMIN >= 72) %>%
      filter(Date < as.Date("1940-03-01")) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      dplyr::select(Date, Year, Month, Day, TMAX, TMIN, PRCP) 
table(DTN2.df$TMIN)

sum(DTN2.df$TMIN >= 77)
```

What is the most likely number of 100 degree days at the airport over the period of record when the daily high temperature was recorded only downtown?
```{r}
n100 <- numeric()
for(i in 1:1000){
  print(i)
HOTday <- add_predicted_draws(newdata = data.frame(TMAX = DTN1.df$TMAX, Date = DTN1.df$Date), 
                              fit1, n = 1000) %>%
  mutate(HOTday = .prediction) %>%
  group_by(Date) %>%
  sample_n(size = 1) %>%
  pull(HOTday) 
n100 <- c(n100, sum(HOTday))
}

n77 <- numeric()
for(i in 1:1000){
  print(i)
HOTnight <- add_predicted_draws(newdata = data.frame(TMIN = DTN2.df$TMIN, Date = DTN2.df$Date), 
                                fit2, n = 1000) %>%
  mutate(HOTnight = .prediction) %>%
  group_by(Date) %>%
  sample_n(size = 1) %>%
  pull(HOTnight) 
n77 <- c(n77, sum(HOTnight))
}

```

Histogram
```{r}
( p2 <- ggplot(as.data.frame(n100), aes(n100)) +
  geom_bar(col = 'white', fill = "gray70") +
    scale_x_continuous(limits = c(0, 40)) +
    xlab("Estimated Number of Hot Days\n at WSO Tallahassee (1892-1939)") + 
    ylab("Frequency") +
    ggtitle("B") +
  theme_minimal() )

ggarrange(p1, p2, ncol = 2, nrow = 1)

range(n100)
median(n100)

ggplot(as.data.frame(n77), aes(n77)) +
  geom_bar(col = 'white', fill = "gray70") +
    scale_x_continuous(limits = c(0, 20)) +
    xlab("Estimated Number of Hot Nights\n at WSO Tallahassee (1892-1939)") + 
    ylab("Frequency") +
  theme_minimal() 

sum(DTN2.df$TMIN >= 77)
sum(OVRhotNights.df$TMIN2 >= 77)
range(n77)
median(n77)
```
###Figure: Model estimates. (A) Probability of getting a 100+F day given the high temperature downtown. (B) Number of hot days at WSO Tallahassee over the period 1892--1939.

Simulate counts using the model over early years. Then concatenate the later years. 
```{r}
N <- 500
p_draws <- add_predicted_draws(newdata = data.frame(TMAX = DTN1.df$TMAX, Date = DTN1.df$Date), 
                               fit1, n = N) %>%
  mutate(Year = year(Date)) %>%
  group_by(.draw, Year) %>%
  summarize(nHotDays = sum(.prediction > 0))

YC_sim.df <- data.frame(Year = seq(1892, 1939, 1))

YC_sim.df <- left_join(YC_sim.df, p_draws, by = "Year")

YC1.df <- ALL.df %>%
      filter(STATION == 'USC00088754') %>%
      mutate(Date = as.Date(DATE),
             Year = year(Date)) %>%
      group_by(Year) %>%
      summarize(.draw = 0,
                nHotDays = sum(TMAX >= 100, na.rm = TRUE)) %>%
      filter(Year < 1940)

YC2.df <- data.frame()
for(i in 0:N){
YC2.df <- ALL.df %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE),
             Year = year(Date)) %>%
      group_by(Year) %>%
      summarize(.draw = i,
                nHotDays = sum(TMAX >= 100, na.rm = TRUE)) %>%
  rbind(YC2.df)
}

YCdays.df <- rbind(YC_sim.df, YC1.df, YC2.df)
```

Compute the trends. Trace plot of the trends. Add the uncorrected value and the value from 1940-2018.
```{r}
library(broom)

Trends <- YCdays.df %>% 
  group_by(.draw) %>%
  do(tidy(glm.nb(nHotDays ~ Year, data = .))) %>%
  filter(term == "Year") %>%
  mutate(Trend = (exp(estimate) - 1) * 100)

( uncorrectedTrend <- Trends[1, ]$Trend )

x <- Trends %>%
  filter(.draw != 0)
( posteriorMedianTrend <- median(x$Trend) )
quantile(x$Trend, probs = c(.25, .75))

p2 <- Trends %>%
  filter(.draw != 0) %>%
ggplot(aes(x = Trend, y = term)) + 
  geom_point(shape = "-", size = 3, col = "red") +
  scale_x_continuous(limits = c(0, 5), position = "right") +
  coord_flip() + 
  geom_point(aes(x = (exp(coef(fitNBMax)[2]) - 1) * 100), col = "orange", size = 3) +
  geom_point(aes(x = uncorrectedTrend), col = 'gray70', size = 3) +
  geom_point(aes(x = posteriorMedianTrend), col = 'red', size = 3) +
  xlab("Trend (%/yr)") + ylab("") +
    ggtitle("B") +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        axis.text.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none")
```

Time series of counts corrected vs uncorrected.
```{r}
YCdays.df <- YCdays.df %>%
  filter(.draw == 1 | .draw == 0) %>%
  mutate(Label = ifelse(.draw, "Corrected", 
                        "Uncorrected"),
         LabelF = factor(Label))

p1 <- ggplot(YC.df, aes(x = Year, y = nHotDays, color = LabelF)) + 
  geom_vline(xintercept = 1939.5, col = "black", lty = 2) +
  stat_smooth(method = "glm.nb",
              formula = y ~ x, 
              se = FALSE) +
  geom_bar(stat = 'identity', color = "white", fill = "gray70") + 
  scale_color_manual(values = c("red", "gray70")) +
  scale_y_continuous(limits = c(0, 20), position = "left") +
  scale_x_continuous(breaks = seq(1890, 2020, 10)) + 
  ylab("Number of Hot Days") + xlab("") +
  facet_wrap(~ Label, nrow = 2, strip.position =  "top") +
  ggtitle("A") +
#  ggtitle(label = expression(paste('Number of days at or above 100', {}^o, " F")),
#          subtitle = "Tallahassee, Florida, USA (1892-2018)") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 11), 
        legend.position = "none") +
#  labs(caption = "Data: Global Historical Climate Network") +
  theme(strip.text.x = element_text(size = 13, hjust = .15),
        axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.minor = element_blank())

ggarrange(p1, p2, widths = c(6, 1))
```
###Figure: Time series of hot day counts by year. Corrected (top) and uncorrected (bottom).

Repeat for TMIN. Simulate counts using the model over early years. Then concatenate the later years. 
```{r}
N <- 500
p_draws <- add_predicted_draws(newdata = data.frame(TMIN = DTN2.df$TMIN, Date = DTN2.df$Date), 
                               fit2, n = N) %>%
  mutate(Year = year(Date)) %>%
  group_by(.draw, Year) %>%
  summarize(nHotNights = sum(.prediction > 0))

YC_sim.df <- data.frame(Year = seq(1892, 1939, 1))

YC_sim.df <- left_join(YC_sim.df, p_draws, by = "Year")

YC1.df <- ALL.df %>%
      filter(STATION == 'USC00088754') %>%
      mutate(Date = as.Date(DATE),
             Year = year(Date)) %>%
      group_by(Year) %>%
      summarize(.draw = 0,
                nHotNights = sum(TMIN >= 77, na.rm = TRUE)) %>%
      filter(Year < 1940)

YC2.df <- data.frame()
for(i in 0:N){
YC2.df <- ALL.df %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE),
             Year = year(Date)) %>%
      group_by(Year) %>%
      summarize(.draw = i,
                nHotNights = sum(TMIN >= 77, na.rm = TRUE)) %>%
  rbind(YC2.df)
}

YCnights.df <- rbind(YC_sim.df, YC1.df, YC2.df)

Trends <- YCnights.df %>% 
  group_by(.draw) %>%
  do(tidy(glm.nb(nHotNights ~ Year, data = .))) %>%
  filter(term == "Year") %>%
  mutate(Trend = (exp(estimate) - 1) * 100)

( uncorrectedTrend <- Trends[1, ]$Trend )

x <- Trends %>%
  filter(.draw != 0)
( posteriorMedianTrend <- median(x$Trend) )
quantile(x$Trend, probs = c(.25, .75))

p2 <- Trends %>%
  filter(.draw != 0) %>%
ggplot(aes(x = Trend, y = term)) + 
  geom_point(shape = "-", size = 3, col = "red") +
  scale_x_continuous(limits = c(0, 5), position = "right") +
  coord_flip() + 
  geom_point(aes(x = (exp(coef(fitNBMin)[2]) - 1) * 100), col = "orange", size = 3) +
  geom_point(aes(x = uncorrectedTrend), col = 'gray70', size = 3) +
  geom_point(aes(x = posteriorMedianTrend), col = 'red', size = 3) +
  xlab("Trend (%/yr)") + ylab("") +
    ggtitle("B") +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        axis.text.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        legend.position = "none")

YCnights.df <- YCnights.df %>%
  filter(.draw == 1 | .draw == 0) %>%
  mutate(Label = ifelse(.draw, "Corrected", 
                        "Uncorrected"),
         LabelF = factor(Label))

p1 <- ggplot(YCnights.df, aes(x = Year, y = nHotNights, color = LabelF)) + 
  geom_vline(xintercept = 1939.5, col = "black", lty = 2) +
  stat_smooth(method = "glm.nb",
              formula = y ~ x, 
              se = FALSE) +
  geom_bar(stat = 'identity', color = "white", fill = "gray70") + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  scale_color_manual(values = c("red", "gray70")) +
  scale_y_continuous(limits = c(0, 25), position = "left") +
  scale_x_continuous(breaks = seq(1890, 2020, 10)) + 
  ylab("Number of Hot Nights") + xlab("") +
  facet_wrap(~ Label, nrow = 2, strip.position =  "top") +
  ggtitle("A") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 9), 
        panel.grid.minor.y = element_blank(),
        legend.position = "none") +
  theme(strip.text.x = element_text(size = 11, hjust = .15),
        axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.minor = element_blank())

ggarrange(p1, p2, widths = c(6, 1))
```
###Figure: Time series of hot night counts by year. Corrected (top) and uncorrected (bottom).

### Stripes

https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/

```{r}
library(stringr)

YCnights1.df <- YCnights.df %>%
  filter(.draw == 1) %>%
  mutate(Date = str_c(Year, "01-01", sep = "-"),
         Date = ymd(Date),
         nHots = nHotNights,
         When = "Nights At or Above 77° F") %>%
  dplyr::select(Date, When, nHots)

YCdays1.df <- YCdays.df %>%
  filter(.draw == 1) %>%
  mutate(Date = str_c(Year, "01-01", sep = "-"),
         Date = ymd(Date),
         nHots = nHotDays,
         When = "Days At or Above 100° F") %>%
  dplyr::select(Date, When, nHots)

YC.df <- rbind(YCnights1.df, YCdays1.df)
```

Set the theme.
```{r}
theme_strip <- theme_minimal() +
                 theme(axis.text.y = element_blank(),
                       axis.line.y = element_blank(),
                       axis.title = element_blank(),
                       panel.grid.major = element_blank(),
                       legend.title = element_blank(),
                       axis.text.x = element_text(angle = 0, vjust = 1),
                       panel.grid.minor = element_blank(),
                       plot.title = element_text(size = 12)
                       )

library(RColorBrewer)

col_strip <- brewer.pal(9, "Oranges")
```

Make the plot.
```{r}
ggplot(YCnights.df, aes(x = Date, y = 1, fill = nHots))+
        geom_tile()+
        scale_x_date(date_breaks = "10 years",
                     date_labels = "%Y",
                     expand = c(0, 0)) +
        scale_y_continuous(expand = c(0, 0)) +
        scale_fill_gradientn(colors = col_strip) +
        guides(fill = guide_colorbar(barwidth = 1)) +
        labs(title = "Number of Hot Nights in Tallahassee: 1892-2018") +
        theme_strip

ggplot(YCdays.df, aes(x = Date, y = 1, fill = nHots)) +
        geom_tile() +
        scale_x_date(date_breaks = "10 years",
                     date_labels = "%Y",
                     expand = c(0, 0)) +
        scale_y_continuous(expand = c(0, 0)) +
        scale_fill_gradientn(colors = col_strip) +
        guides(fill = guide_colorbar(barwidth = 1)) +
        labs(title = "Number of Hot Days in Tallahassee: 1892-2018") +
        theme_strip
```

Plot together.
```{r}

YC.df <- YC.df %>%
  mutate(Label = ifelse(When == "Days",  
                        "Number of Days At or Above 100° F in Tallahassee, FL, USA", 
                        "Number of Nights At or Above 77° F in Tallahassee, FL, USA"))

ggplot(YC.df, aes(x = Date, y = 1, fill = nHots)) +
#        geom_tile(show.legend = FALSE) +
        geom_tile() +
        facet_wrap(~ Label, nrow = 2) + 
          scale_x_date(breaks = c(as.Date("1892-01-01"), as.Date("2018-01-01")),
                      date_labels = "%Y",
                      expand = c(0, 0)) +
        scale_y_continuous(expand = c(0, 0)) +
        scale_fill_gradientn(colors = col_strip) +
        guides(fill = guide_colorbar(barwidth = 1)) +
 #       labs(title = "Number of Hot Days/Nights in Tallahassee: 1892-2018") +
        theme_strip
#        theme_void()
```
