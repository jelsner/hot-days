---
title: "Hot Days in Tallahassee"
author: "James Elsner and Svetoslava Elsner"
date: "5/16/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

### The hots are getting hotter: A statistical analysis of extremely hot days in Tallahassee, FL, USA: 1940-2018

About the climate in Tallahassee.
http://weatherspark.com/history/31772/2013/Tallahassee-Florida-United-States
http://www.fao.org/geonetwork/srv/en/main.home

Airport weather station site location 30.39306°, -84.35333°
Downtown weather station site location 30.43333°, -84.28333°
Compare with Albany GA?

Raster map. Close up.
```{r}
Sites.df <- data.frame(Name = c("Regional Airport", "Downtown", 
                                "Dale Mabry Field", "Municipal Airport"), 
                       Latitude = c(30.39306, 30.43333, 30.44, 30.38),
                       Longitude = c(-84.35333, -84.28333, -84.338, -84.37))
```

```{r}
library(ggmap)

register_google(key = "AIzaSyC06KYSrBr-blWhA_jy24qTEgnY27CUtBg")
getOption("ggmap")

geocode("Tallahassee Airport")

g_map <- get_googlemap(center = c(lon = -84.325, lat = 30.41),
                    zoom = 13, scale = 2,
                    maptype = 'satellite',
                    color = 'color')

cds <- attr(g_map, "bb")

bbx <- st_sfc(st_polygon(list(matrix(c(cds$ll.lon, cds$ur.lat,
                     cds$ur.lon, cds$ur.lat,
                     cds$ur.lon, cds$ll.lat,
                     cds$ll.lon, cds$ll.lat,
                     cds$ll.lon, cds$ur.lat), ncol = 2, byrow = TRUE))),
              crs = 4326)

p <- ggmap(g_map)

mainMap <- p + 
    geom_point(aes(x = Longitude, y = Latitude), 
               data = Sites.df, size = 2, col = c("orange", "red", "orange", "orange")) +
    geom_label(aes(x = Longitude, y = Latitude, label = Name), 
             data = Sites.df,
             nudge_y = -.0025,
             nudge_x = .005) +
    theme_void() +
    theme(legend.position = "none")
```

Create a map with an inset showing Florida.
```{r}
library(sf)
library(dplyr)

library(tmap)
library(USAboundaries)

FL.sf <- us_states(states = "Florida")
FL.sf$name <- "            Florida"
ALGA.sf <- us_states(states = c("Alabama", "Georgia"))

Leon.sf <- us_counties(states = "FL") %>%
  filter(name == "Leon")

inset.tm <- 
    tm_shape(FL.sf, projection = "laea_NA") +
       tm_polygons(col = "white") +
       tm_text(text = "name", size = 1) +
    tm_shape(ALGA.sf) +
       tm_polygons(col = "gray") +
    tm_shape(Leon.sf) +
       tm_borders() +
    tm_shape(bbx) +
       tm_polygons(col = "black") +
    tm_compass(type = "arrow", position = c("left", "bottom")) +
    tm_scale_bar(position = c("left", "bottom"), size = .55) +
    tm_style("natural")

library(grid)

mainMap
print(inset.tm, vp = viewport(.75, .25, width = .7, height = .4))
```
###Figure: Location map. Tallahassee. Map of Tallahassee showing the locations of the two temperature records.



Get the data. Ordered online from 
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail
 Elev: 55 ft. Lat: 30.3931° N Lon: -84.3533° W

TALLAHASSEE REGIONAL AIRPORT, FL US (Station ID: GHCND:USW00093805)
TALLAHASSEE, FL US (Station ID: GHCND:USC00088754)

Sofia Bulgaria
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:BUM00015614/detail

https://docs.opendata.aws/noaa-ghcn-pds/readme.html

## Hot days and nights

Get data.
```{r}
library(lubridate)

TLH.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), 
             Month = month(Date), 
             Day = day(Date),
             doy = yday(Date)) %>%
      select(Date, Year, Month, Day, doy, TMAX, TMIN, PRCP)
```

Add temperatures for July 8, 2005 from Weather Underground.
```{r}
TLH.df$Date[is.na(TLH.df$TMAX)]
TLH.df$Date[is.na(TLH.df$TMIN)]

TLH.df$TMAX[TLH.df$Date == "2005-07-08"] <- 96
TLH.df$TMIN[TLH.df$Date == "2005-07-08"] <- 71
TLH.df$TMIN[TLH.df$Date == "2002-10-08"] <- TLH.df$TMIN[TLH.df$Date == "2002-10-07"]
```

Histogram of daily high temperature.
```{r}
FreqByT <- TLH.df %>%
#  filter(Month >= 5 & Month <= 9) %>%
#    filter(Year < 1980) %>%
  group_by(TMAX) %>%
  summarize(nH = n())
FreqByT2 <-FreqByT %>%
  filter(TMAX >= 100)

( p1 <- ggplot(FreqByT, aes(x = TMAX, y = nH)) +
  geom_bar(stat = 'identity', col = 'white', fill = "gray70") +
  geom_bar(data = FreqByT2, stat = 'identity', fill = "orange") +
  scale_x_continuous(breaks = seq(40, 100, 10),
                     labels = paste0(seq(40, 100, 10), "°")) +
  scale_y_continuous(position = "right", limits = c(0, 1600)) +
  ylab("") +  xlab("") +
#  ggtitle(label = "Frequency of Daily High Temperatures",
#          subtitle = "Tallahassee, FL, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) )

FreqByT <- TLH.df %>%
#    filter(Month >= 5 & Month <= 9) %>%
#  filter(Year < 1980) %>%
  group_by(TMIN) %>%
  summarize(nH = n())
FreqByT2 <-FreqByT %>%
  filter(TMIN >= 77)

(p2 <- ggplot(FreqByT, aes(x = TMIN, y = nH)) +
  geom_bar(stat = 'identity', col = 'white', fill = "gray70") +
  geom_bar(data = FreqByT2, stat = 'identity', fill = "orange") +
  scale_x_continuous(breaks = seq(20, 80, 10),
                     labels = paste0(seq(20, 80, 10), "°")) +
  scale_y_continuous(position = "right", limits = c(0, 1600)) +
  ylab("") + xlab("") +
#  ggtitle(label = "Frequency of Daily Low Temperatures",
#          subtitle = "Tallahassee, FL, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) )

library(ggpubr)

ggarrange(p1, p2, 
          nrow = 2, 
          labels = c("Number of Days by Maximum Temperature", 
                     "Number of Days by Minimum Temperature"),
          font.label = list(face = "plain", size = 11))
```
###Figure: The number of days by high temperature (top) and by low temperature (bottom).

We consider only the extreme right tail of the distribution defined as days in which the high temperature reached or exceeded 100F. The number of days that it reached 98 is 202, 99 is 111, 100 is 70 and 101 is 24. While arbitrary, the century mark adds a psychological component to the perception of a hot day providing a way to anchor the results of this study to a well understood threshold.

The most common high temperature is 90F and the most common low temperature is 72F. The modes are close to the right-tail extremes (high: 100+, low: 77+).

Definitions: hot day: high temperature reaches 100F. hot night: low temperature fails to fall below 77F.

How many hot days/nights? Median date. Seasonal variability.
```{r}
TLH.df %>%
  summarize(nD = n(),
            N100 = sum(TMAX >= 100),
            N77 = sum(TMIN >= 77),
            qtle100 = 1 - N100/nD,
            qtle77 = 1 - N77/nD)
```

The 99.555th percentile of the distribution of daily high temperatures in the observations. 4 days in 1000. The 99.4368th percentile of the distribution of daily low temperatures.

Monthly counts.
```{r}
TLH.df %>%
  group_by(Month) %>%
  summarize(N100 = sum(TMAX >= 100, na.rm = TRUE),
            N77 = sum(TMIN >= 77, na.rm = TRUE)) %>%
  filter(Month %in% 5:10) %>%
  mutate(MonthName = month.name[Month]) %>%
  dplyr::select(MonthName, N100, N77)
```
###Table: Monthly counts.

The potential for a hot day or a hot night in Tallahassee begins in May. A hot day has never been recorded after August but there have been hot nights in September and even a few in October. The frequency of hot days peaks in June where as the frequency of hot nights peaks in August. 

Seasonality. 
```{r}
TLH.df %>%
  filter(TMAX >= 100) %>%
  summarize(medianDate = median(doy))

# 182: July 1st
TLH.df %>%
  filter(TMIN >= 77) %>%
  summarize(medianDate = median(doy))
# 216: August 4th

library(reshape2)

DOY <- TLH.df %>%
  group_by(doy) %>%
  summarize("Number of Times the Daily High Reached 100° F" = sum(TMAX >= 100, na.rm = TRUE),
            "Number of Times the Daily Low Remained Above 77° F" = sum(TMIN >= 77, na.rm = TRUE)) %>%
  filter(doy %in% 139:250) %>%
  melt(id.vars = "doy")

ggplot(DOY, aes(x = doy, y = value)) +
  geom_bar(stat = 'identity', col = "white", fill = "orange") +
  scale_x_continuous(position = "bottom", 
                     breaks = c(152, 166, 182, 196, 213, 227, 244),
                     labels = c("June 1", "June 15", 
                                "July 1", "July 15", 
                                "August 1", "August 15",
                                "September 1")) +
  scale_y_continuous(position = "left") +
  facet_wrap(~ variable, nrow = 2, strip.position = "top") +
  ylab("") + xlab("") +
#  ggtitle(label = "Number of Extremely Hot Days & Nights By Day of Year",
#          subtitle = "Tallahassee, Florida, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(),
        strip.text.x = element_text(size = 11),
        legend.position = "none") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) 
```
###Figure: Number of times by day of the year the daily high reached 100F (top) and number of times the daily low remained at or above 77F.

This seasonal difference between hot days and nights is evident in Fig.~\ref{}. The frequency distribution of hot day occurrence by day of year is skewed toward early summer. In contrast the frequency distribution of hot night occurrence is skewed toward mid to late summer. The median date for a hot day is July 1st and the median date for a hot night is August 6th.

NOT USED
```{r}
dailyRecs <- TLH.df %>% 
  group_by(Month, Day) %>%
  summarize(dMaxMax = max(TMAX, na.rm=TRUE),
            dMaxMin = max(TMIN, na.rm=TRUE),
            dMaxMaxY = Year[which.max(TMAX)],
            dMaxMinY = Year[which.max(TMIN)])

dailyRecs %>%
  group_by(dMaxMaxY) %>%
  summarize(count = length(dMaxMaxY)) %>%
ggplot(aes(x = dMaxMaxY, y = count)) +
  geom_bar(stat = 'identity') +
  ylab("Number of dates having the daily record high maximum")

dailyRecs %>%
  group_by(dMaxMinY) %>%
  summarize(count = length(dMaxMinY)) %>%
ggplot(aes(x = dMaxMinY, y = count)) +
  geom_bar(stat = 'identity') +
  ylab("Number of dates having the daily record high minimum")
```

Annual time series of extreme counts.
```{r}
library(MASS)
TLH.df %>% 
  group_by(Year) %>%
  summarize("High Temperature At Or Above 100°"  = sum(TMAX >= 100, na.rm = TRUE),
            "Low Temperature At Or Above 77°" = sum(TMIN >= 77, na.rm = TRUE)) %>%
  melt(id.vars = "Year") %>%
ggplot(aes(x = Year, y = value, fill = value)) + 
  geom_bar(stat='identity') + 
     stat_smooth(method = "glm.nb",
                 formula = y ~ x, 
                 se = FALSE,
                 col = "green") +
  scale_fill_continuous(low = 'orange', high = 'red') +
  scale_x_continuous(position = "top", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(limits = c(0, 25), position = "right") +
#  geom_text(aes(label = value), vjust = -.5, size = 2.5) +
  facet_wrap(~ variable, nrow = 2, strip.position = "bottom") +
  ylab("") + xlab("") +
  ggtitle(label = "Number of Extremely Hot Days & Nights",
          subtitle = "Tallahassee, Florida, USA (1940-2018)") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank(),
        strip.text.x = element_text(size = 11),
        legend.position = "none") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) 

TLH.df %>% 
  group_by(Year) %>%
  summarize(N100 = sum(TMAX >= 100)) %>%
  arrange(desc(N100))

TLH.df %>% 
  group_by(Year) %>%
  summarize(N77 = sum(TMIN >= 77)) %>%
  arrange(desc(N77))
```
### Figure: Time series of the number of extremely hot days and nights.

Counts of hot days and nights by year show upward trends since 1940. The trend is more pronounced for the occurrence of hot nights. Only relatively few years had hot days or nights before 1980. Since then more years than not have at least one hot day and night. There were 16 hot days in 1998, 14 in 2011 and 11 in 2000. There were 21 hot nights in 2010, 15 in 20115, 14 in 2016 and 13 in 2005.

Quantify the trend.
```{r}
Yearly.df <- TLH.df %>% 
  group_by(Year) %>%
  summarize(MaxCount  = sum(TMAX >= 100),
            MinCount = sum(TMIN >= 77))

var(Yearly.df$MaxCount)/mean(Yearly.df$MaxCount)
var(Yearly.df$MinCount)/mean(Yearly.df$MinCount)

coef(glm.nb(MaxCount ~ 1, data = Yearly.df))  # .49 annual rate of 100+F days
coef(glm.nb(MaxCount ~ Year, data = Yearly.df)) # 2.1% per year increase in annual rate

coef(glm.nb(MinCount ~ 1, data = Yearly.df))  # .71 annual rate of 100+F days
coef(glm.nb(MinCount ~ Year, data = Yearly.df)) # 4.5% per year increase in annual rate

fitNB <- glm.nb(MaxCount ~ Year, data = Yearly.df)
fitPO <- glm(MaxCount ~ Year, data = Yearly.df, family = "poisson")
AIC(fitNB); AIC(fitPO)

pchisq(2 * (logLik(fitNB) - logLik(fitPO)), df = 1, lower.tail = FALSE)

predict(fitNB, newdata = data.frame(Year = 1940), type = "response", se = TRUE)
predict(fitNB, newdata = data.frame(Year = 2018), type = "response", se = TRUE)
```

What does an annual rate of .63 mean? It means that we can expect a 1 - exp(-.63) = 47% chance of at least one 100F day per year.

An annual rate of 3.2 means we can now expect a 1 - exp(-3.2) = 96% chance of at least one 100F day per year.

### Hot events

Atmospheric conditions that produce extremely hot days in Tallahassee are broad scale. This means that the high pressure ridge producing subsidence and keeping the air relatively dry spreads across several states often encompassing the entire southeast. The occurrence of a 100$+^\circ$F day is often followed by a better than average chance of another hot day.

Consecutive hot days tend to result in the hottest days. As a consequence of this clustering, it is useful to consider hot events. Here a hot event is defined as one or more days in which the temperature reaches at least 100F. An event might consist of a single day or it may consist of several consecutive days (heat wave).

Determine hot events (day).
```{r}
hotEvents <- rle(TLH.df$TMAX >= 100)

eventLength <- hotEvents$lengths[hotEvents$values]
eventNo <- rep(1:length(eventLength), eventLength)

Events.df <- TLH.df %>%
  filter(TMAX >= 100) %>%
  mutate(eventNo = eventNo)
```

Determine the number of days between successive 100+F days. Add this as another column.
```{r}
Events.df <- Events.df %>%
  mutate(daysBetween = Date - lag(Date))

Events.df %>%
  arrange(desc(daysBetween))
```

Length and intensity of events.
```{r}
LI.df <- Events.df %>%
  group_by(eventNo) %>%
  summarize(eventLength = n(),
              avgEventT = mean(TMAX),
              maxEventT = max(TMAX),
              whenMaxEvT = which.max(TMAX),
              Year = Year[1])

# empirical chance of another 100+F day (41.4% chance)
sum(LI.df$eventLength > 1)/length(LI.df$eventLength) 

cor(LI.df$eventLength, LI.df$maxEventT, method = "s") # .55

LI2.df <- LI.df %>%
  group_by(Year) %>%
  summarize(count = n(),
            avgEL = mean(eventLength))

AllYears <- data.frame(Year = 1940:2018)
LI3.df = merge(AllYears, LI2.df, by = "Year", all.x = TRUE)
LI3.df$count[is.na(LI3.df$count)] = 0

var(LI3.df$count)/mean(LI3.df$count) # 2.46

library(MASS)
(p1 <- ggplot(data = LI3.df, aes(x = Year, y = count)) +
   geom_point(col = "gray70") +
#   stat_smooth(method = "glm.nb",
#              formula = y ~ x, 
#              data = LI3.df, se = TRUE) +
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2), position = "left") +
  ylab("") + xlab("") +
  theme_minimal() +
    ggtitle("Number of daytime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) )
  

##NOT used
ggplot(data = LI3.df, aes(x = Year, y = count)) +
   geom_point() +
   stat_smooth(method = "glm",
               method.args = list(family = "poisson"),
               formula = y ~ x, 
               se = TRUE) 

(p2 <- ggplot(data = LI3.df, aes(x = Year, y = avgEL)) +
   geom_bar(stat = "identity", fill = "gray70") +
#  stat_smooth(method = "glm",
#               method.args = list(family = "Gamma"),
#               formula = y ~ x, 
#               se = TRUE)
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(position = "left", breaks = seq(1, 8, 1)) +
  ylab("") + xlab("") +
  theme_minimal() +
    ggtitle("Average length (days) of daytime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) )

ggarrange(p1, p2, nrow = 2)
```
###Figure: Frequency and duration of hot daytime events.

Determine hot events (night).
```{r}
hotEvents <- rle(TLH.df$TMIN >= 77)

eventLength <- hotEvents$lengths[hotEvents$values]
eventNo <- rep(1:length(eventLength), eventLength)

Events.df <- TLH.df %>%
  filter(TMIN >= 77) %>%
  mutate(eventNo = eventNo)
```

Determine the number of days between successive 77+F nights. Add this as another column.
```{r}
Events.df <- Events.df %>%
  mutate(daysBetween = Date - lag(Date))

Events.df %>%
  arrange(desc(daysBetween))
```

Length and intensity of events.
```{r}
LI.df <- Events.df %>%
  group_by(eventNo) %>%
  summarize(eventLength = n(),
              avgEventT = mean(TMIN),
              maxEventT = max(TMIN),
              whenMaxEvT = which.max(TMIN),
              Year = Year[1])

# empirical chance of another 77+F night (23.3%)
sum(LI.df$eventLength > 1)/length(LI.df$eventLength) 

cor(LI.df$eventLength, LI.df$maxEventT, method = "s") # .54

LI2.df <- LI.df %>%
  group_by(Year) %>%
  summarize(count = n(),
            avgEL = mean(eventLength))

AllYears <- data.frame(Year = 1940:2018)
LI3.df = merge(AllYears, LI2.df, by = "Year", all.x = TRUE)
LI3.df$count[is.na(LI3.df$count)] = 0

var(LI3.df$count)/mean(LI3.df$count)

(p1 <- ggplot(data = LI3.df, aes(x = Year, y = count)) +
  geom_point(col = "gray70") +
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(limits = c(0, 14), breaks = seq(0, 14, 2), position = "left") +
  ylab("") + xlab("") +
  theme_minimal() +
    ggtitle("Number of nighttime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) )

(p2 <- ggplot(data = LI3.df, aes(x = Year, y = avgEL)) +
   geom_bar(stat = "identity", fill = "gray70") +
  scale_x_continuous(position = "bottom", breaks = seq(1945, 2015, by = 10)) +
  scale_y_continuous(position = "left", breaks = seq(1, 8, 1)) +
  ylab("") + xlab("") +
  theme_minimal() +
    ggtitle("Average length (nights) of nighttime hot events") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) )

ggarrange(p1, p2, nrow = 2)
```
###Figure: Frequency and duration of hot nighttime events.

### Analysis of temperatures when data are available at both sites

```{r}
df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) 

duplicateRows <- duplicated(df$Date)
duplicateDates <- df$Date[duplicateRows]

df1 <- df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USC00088754")

df2 <- df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USW00093805") %>%
  select(STATION2 = STATION, TMAX2 = TMAX, TMIN2 = TMIN, PRCP2 = PRCP)

dfOverlap <- cbind(df1, df2)
```

```{r}
dfOverlap <- dfOverlap %>%
  mutate(OLDwarmer = TMAX - TMAX2 > 0,
         OLDcolder = TMAX - TMAX2 < 0)

sum(dfOverlap$OLDwarmer[dfOverlap$TMIN >= 78], na.rm = TRUE)
sum(dfOverlap$OLDcolder[dfOverlap$TMIN >= 78], na.rm = TRUE)

mean(dfOverlap$TMAX, na.rm = TRUE)
mean(dfOverlap$TMAX2, na.rm = TRUE)

mean(dfOverlap$TMIN, na.rm = TRUE)
mean(dfOverlap$TMIN2, na.rm = TRUE)

mean(dfOverlap$TMAX[dfOverlap$TMAX >= 95], na.rm = TRUE)
mean(dfOverlap$TMAX2[dfOverlap$TMAX >= 95], na.rm = TRUE)

mean(dfOverlap$TMAX[dfOverlap$TMAX >= 100], na.rm = TRUE)
mean(dfOverlap$TMAX2[dfOverlap$TMAX >= 100], na.rm = TRUE)

```
The overall daily high temperature means are nearly identical. For hot days the difference in average highs is in favor of downtown.

Daily temperatures in Tallahassee were recorded from a station downtown until the early 1940s. Since then at the airport. Avg difference in highs during the overlap period is small (less than 1/2°F). But it is much more likely to get to 100°F+ downtown. 

Cumulative logistic regression model. Note: The model cannot predict temperatures above 100 at the airport since there were none in the record during the overlapping years. It can assign an exceedance probability for a larger range of input temperatures.
```{r}
library(brms)

minTMAX2 <- min(dfModel2$TMAX2)

dfModel2 <- dfModel %>%
  filter(TMAX >= 94) %>%
  mutate(TI = TMAX2 - minTMAX2 + 1,
         TDT = scale(TMAX))

family <- brms::cumulative(threshold = "equidistant")
formula <- TI ~ 1

get_prior(formula, data = dfModel2, family = family)

fit0 <- brm(formula = formula,
           data = dfModel2,
           family = family,
           prior = set_prior("student_t(3, 0, 10)", class = "Intercept"),
           seed = 9121)
fixef(fit0)

fit0_out <- predict(fit0, probs = c(0, 1))
head(fit0_out)

formula <- TI ~ TMAX

get_prior(formula, data = dfModel2, family = family)

fit1 <- brm(formula = formula,
            data = dfModel2,
            family = family,
            prior = c(set_prior("normal(0, 1)", class = "b"),
                     set_prior("student_t(7, 0, 10)", class = "Intercept")),
           seed = 78121)

summary(fit1)

library(tidybayes)
library(modelr)

# initialize out data frame
out <- dfModel2 %>%
  data_grid(TMAX = 96:106) %>%
  add_predicted_draws(fit1, n = 1000) %>%
  mutate(pTMAX2 = as.integer(.prediction)  + minTMAX2 - 1) %>%
  group_by(TMAX) %>%
  summarize(nTMAX = n(),
            prob100 = sum(pTMAX2 >= 100)/nTMAX) 

out

# rbind to the initialized data frame
for(i in 2:100){
  out <- dfModel2 %>%
  data_grid(TMAX = 96:106) %>%
  add_predicted_draws(fit1, n = 1000) %>%
  mutate(pTMAX2 = as.integer(.prediction)  + minTMAX2 - 1) %>%
  group_by(TMAX) %>%
  summarize(nTMAX = n(),
            prob100 = sum(pTMAX2 >= 100)/nTMAX) %>%
    rbind(out)
}

out$I <- rep(1:100, each = 11)

library(ggridges)

ggplot(out, aes(x = TMAX, y = prob100, group = I)) +
  geom_point(alpha = .2, size = .5) +
  scale_x_continuous(breaks = 96:106) +
  xlab("High Temperature Downtown Tallahassee (°F)") +
  ylab("Posterior Probability") +
  ggtitle("Chance the TLH Airport Reports a 100+°F Day",
          subtitle = "Given specific high temperatures downtown") +
  theme_minimal() +
  theme(panel.grid.minor.x = element_blank())
```

Read only the data from the downtown site. Filter by days at or above 96F then use the model to predict the temperature at the airport. August 31, 1895 TMAX = 2768 is removed.
```{r}
DTN.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USC00088754') %>%
      filter(TMAX >= 96) %>%
      filter(TMAX != 2768) %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP) 
table(DTN.df$TMAX)
```

Predictions. What is the likely number of 100 degree days at the airport over the period of record when the daily high temperature was recorded downtown?
```{r}
n100 <- numeric()
for(i in 1:100){
TMAX2 <- add_predicted_draws(newdata = data.frame(TMAX = DTN.df$TMAX, Date = DTN.df$Date), 
                    fit1, n = 1000) %>%
  mutate(TMAX2est = as.integer(.prediction) + minTMAX2 - 1) %>%
  group_by(Date) %>%
  sample_n(size = 1) %>%
  pull(TMAX2est) 
n100 <- c(n100, sum(TMAX2 >= 100))
}
```

Predictions. No loop. Look at three realizations from the model. Join predictions data frame with the original downtown data frame.
```{r}
x <- add_predicted_draws(newdata = data.frame(TMAX = DTN.df$TMAX, Date = DTN.df$Date), 
                    fit1, n = 1000) %>%
  mutate(TMAX2est = as.integer(.prediction) + minTMAX2 - 1) %>%
  group_by(Date) %>%
  sample_n(size = 3) %>%
  pull(TMAX2est)

z <- data.frame(matrix(x, ncol = 3, byrow = FALSE))
names(z) <- c("C1", "C2", "C3")
z$Date <- DTN.df$Date

YearCount.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USC00088754') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP) %>%
left_join(z, by = "Date") %>%
  filter(Date < as.Date("1940-03-01")) %>%
  group_by(Year) %>%
  summarize(C1 = sum(C1 >= 100, na.rm = TRUE),
            C2 = sum(C2 >= 100, na.rm = TRUE),
            C3 = sum(C3 >= 100, na.rm = TRUE),
            Uncorrected = sum(TMAX >= 100, na.rm = TRUE))
```

Read only the data from the airport site.
```{r}
TLH.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP)
```

```{r}
YearCount2.df <- TLH.df %>%
  group_by(Year) %>%
  summarize(C1 = sum(TMAX >= 100, na.rm = TRUE),
            C2 = sum(TMAX >= 100, na.rm = TRUE),
            C3 = sum(TMAX >= 100, na.rm = TRUE),
            Uncorrected = C1)

library(reshape2)
YC.df <- rbind(YearCount.df, YearCount2.df) %>%
  melt(id.vars = "Year") %>%
  mutate(variable = factor(variable, 
                           levels = c("Uncorrected", 
                                      "C1", "C2", "C3")))
levels(YC.df$variable) <- c("Raw", "Corrected 1", "Corrected 2", "Corrected 3")

ggplot(YC.df, aes(x = Year, y = value, fill = value)) + 
  geom_bar(stat='identity') + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  geom_text(aes(label = value), vjust = -.5, size = 3) +
  scale_y_continuous(limits = c(0, 25), position = "right") +
  ylab("Number of Days") +
  facet_wrap(~ variable, nrow = 4, strip.position =  "bottom" ) +
  ggtitle(label = expression(paste('Number of days at or above 100', {}^o, " F")),
          subtitle = "Tallahassee, Florida, USA (1892-2018)") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 11), 
        legend.position = "none") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50"))

```
* TMAX: Daily maximum temperature, 
* TMIN: Daily minimum temperature, 
* PRCP: Daily total precipitation, 
* WDF1: Wind direction of fastest one-minute wind, 
* WSF1: Wind speed of fastest one-minute wind

Check for missing values in maximum and minimum temperature
```{r}
sum(is.na(TLH.df$TMAX))
TLH.df$Date[is.na(TLH.df$TMAX)]
TLH.df$Date[is.na(TLH.df$TMIN)]
```

Add temperatures for July 8, 2005 from Weather Underground.
```{r}
TLH.df$TMAX[TLH.df$Date == "2005-07-08"] <- 96
TLH.df$TMIN[TLH.df$Date == "2005-07-08"] <- 71
```

Line plot of the average annual daily high (low) temperature.
https://cedricscherer.netlify.com/2019/05/17/the-evolution-of-a-ggplot-ep.-1/
```{r}
library(ggplot2)

TLH.df %>% 
  filter(Year >= 1941, TMIN >= 77) %>%
  group_by(Year) %>%
  summarize(avgT = mean(TMIN, na.rm = TRUE)) %>%
#  summarize(avgP = mean(PRCP, na.rm = TRUE)) %>%
ggplot(aes(x = Year, y = avgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab(expression(paste('Temperature (', {}^o, " F)"))) +
  ggtitle(label = "Annual Average Daily High Temperature",
          subtitle = "Tallahassee, Florida, USA (1941-2018)") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) +
  theme_bw()
```

Last hot days?
```{r}
df %>% 
  filter(TMAX >= 100 & Month == 5) %>%
  arrange(desc(Date)) %>%
  head(n = 20)

df %>%
  arrange(desc(TMAX)) %>%
  head()
```

Hot days since 2009.
```{r}
hotDates <- df %>%
  filter(Year >= 2009 & TMAX >= 100) %>%
  select(Date) %>%
  pull()
```

Hourly data.
```{r}
dfH <- read.csv(file = "TLH_Hourly2009.csv", 
                header = TRUE,
                stringsAsFactors = FALSE)
str(dfH)
```

Report type: https://www1.ncdc.noaa.gov/pub/data/ish/ish-format-document.pdf

FM-12 = SYNOP Report of surface observation form a fixed land station
FM-15 = METAR Aviation routine weather report
FM-16 = SPECI Aviation selected special weather report

Convert the date/time character string to a data/time obect.
```{r}
library(lubridate)

dfH2 <- dfH %>%
  mutate(DateTime = ymd_hms(DATE, tz = "EST"),
         Date = as.Date(DateTime, tz = "EST"),
         TempF = as.integer(HourlyDryBulbTemperature),
         ReportType = REPORT_TYPE) %>%
  select(ReportType, DateTime, Date, TempF) %>%
  filter(Date %in% hotDates) %>%
  filter(ReportType == 'FM-15')
```

Consecutive hours at or above 100F.
```{r}
hotTimes <- rle(dfH2$TempF >= 100)
consecHours <- hotTimes$lengths[hotTimes$values]
consecHours <- consecHours[!is.na(consecHours)]

dfH2 <- dfH2 %>%
  filter(TempF >= 100) %>%
  mutate(dateNo = rep(1:length(consecHours), consecHours))
```

Join the daily data with the hourly data.
```{r}
df2 <- df %>%
  select(Date, TMAX) %>%
  filter(TMAX >= 100)

dfH2 <- left_join(dfH2, df2)
```

Round the times to nearest hour.
```{r}
dfH2 <- dfH2 %>%
  mutate(Hour =  hour(round(DateTime, "hours")))
```

### Compare with the standard model

Compare with the number of 90F days. The upward trend starts at 95F. No changes in temps lower than that. This contrasts with the standard model where we expect upward trends in all temperatures above the average temperature.
```{r}
TLH.df %>% 
#  filter(Month >= 5 & Month <= 9) %>%
  group_by(Year) %>% 
  summarize(n90 = sum(TMAX == 78)) %>% 
#  summarize(mT = mean(TMAX)) %>%
  ggplot(aes(Year, n90)) + 
  geom_point() +
  geom_smooth(method = lm)
```

Start with a random distribution of high temps using a normal density.
```{r}
TLH.df %>%
  group_by(Year < 1980) %>%
  summarize(avgHighT = mean(TMAX),
            avgLowT = mean(TMIN),
            medianHighT = median(TMAX),
            medianLowT = median(TMIN),
            sdHighT = sd(TMAX),
            sdLowT = sd(TMIN))

Random.df <- data.frame(rT = c(round(rnorm(n = 1000000, mean = 79, sd = 12.1)),
                               round(rnorm(n = 1000000, mean = 80.1, sd = 12.2))),
                        Epoch = c(rep("1940-1979", each = 1000000),
                                  rep("1980-2018", each = 1000000)))

FreqByRandomT <- Random.df %>%
  group_by(Epoch, rT) %>%
  summarize(nH = n()) %>%
  group_by(Epoch) %>%
  mutate(nDays = sum(nH),
         perc = nH/nDays)

ggplot(FreqByRandomT[FreqByRandomT$rT >= 80 & FreqByRandomT$rT <= 105 , ], aes(x = rT, y = perc, color = Epoch)) +
  geom_line(size = 1) +
  scale_y_continuous(position = "right") +
  scale_color_manual(labels = c("1940-1979", "1980-2018"), values = c("blue", "red")) +
  ylab("") +  xlab("") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) 
```

Repeat for actual temperatures.
```{r}
FreqByT <- TLH.df %>%
  mutate(Epoch = Year <= 1980) %>%
  group_by(Epoch, TMAX) %>%
  summarize(nH = n()) %>%
  group_by(Epoch) %>%
  mutate(nDays = sum(nH),
         perc = nH/nDays)

ggplot(FreqByT[FreqByT$TMAX >= 80, ], aes(x = TMAX, y = perc, color = Epoch)) +
#  geom_line() +
  stat_smooth(method = "loess", formula = y ~ x, span = .34, size = 1, se = FALSE) +
  scale_x_continuous(breaks = seq(80, 104, 2),
                     labels = paste0(seq(80, 104, 2), "°")) +
  scale_y_continuous(position = "right") +
  scale_color_manual(labels = c("1980-2018", "1940-1979"), values = c("red", "blue")) +
  ylab("") +  xlab("") +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) 
```
