---
title: "Hot Days in Tallahassee"
author: "James Elsner and Svetoslava Elsner"
date: "5/16/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

### Lede: The hots are getting hotter

Here we look at the statistics of extremely hot days in Tallahassee, Florida. An extremely hot day is defined as one in which the maximum temperature exceeds 100$+^\circ$ F.  A record of daily maximum temperatures from the regional airport reveals an increasing trend in the occurrence of such days since the 1970s. The trend results from an increase in the occurrence of hot events and an increase in the average length of an event. We speculate that the trend is related to changes in the intensity and location of deep layer ridging, perhaps exacerbated by changes in land use and global warming.

The combination of heat and humidity is expected to reach excessive, unhealthy levels. In particular, this event is early in the season when people are less acclimated to the heat, and this is expected to be a long duration event. These factors tend to exacerbate any heat related illness. The most vulnerable populations include the elderly, homeless, and those with medical conditions, especially
where there is a lack of air conditioning. With the holiday weekend, outdoor event goers will also have an increased risk for heat related illness. There is also a larger than normal population without air conditioning in areas recovering from Hurricane Michael.

The dry air mass will allow for efficient solar heating today. Highs will be in the upper 90s and near 100 away from the immediate coast. A Heat Advisory is in effect today through Monday in the areas hit hardest by Hurricane Michael. Due to deforestation, temps may be a few degrees hotter in these locations.

Deep layer ridging, loss of daytime heating

Compare with Albany GA

About the climate in Tallahassee.
http://weatherspark.com/history/31772/2013/Tallahassee-Florida-United-States

Need a map with inset. See file:///Users/jameselsner/Desktop/ClassNotes/appl-spat-stat/09-Lesson.html

```{r}
library(dplyr)
library(lubridate)
```

Airport weather station site location 30.39306°, -84.35333°
Downtown weather station site location 30.43333°, -84.28333°

```{r}
TLH_site.df <- data.frame(name = "TLH            ", 
                          lon = -84.35333, 
                          lat = 30.39306)
TLH_site.sf <- st_as_sf(TLH_site.df, 
                        coords = c("lon", "lat"))
st_crs(TLH_site.sf) <- 4326
```
```{r}
library(tmap)
library(spData)

FL1.sf <- us_states %>%
  filter(NAME == "Florida")

( inset.tm <- tm_shape(world) +
  tm_polygons() +
tm_shape(world[world$name_long == "United States", ]) +
  tm_polygons(col = "gray") +
tm_shape(us_states, projection = "laea_NA", is.master = TRUE) + 
  tm_borders() +
  tm_compass(type = "arrow", position = c("left", "bottom")) +
  tm_scale_bar(position = c("left", "bottom"), size = .75) +
  tm_style("natural") +
tm_shape(FL1.sf) +
  tm_polygons(col = "white") )

library(USAboundaries)

FL.sf <- us_states(states = "Florida")
FL.sf$name <- "            Florida"
ALGA.sf <- us_states(states = c("Alabama", "Georgia"))

( main.tm <- 
    tm_shape(FL.sf, projection = "laea_NA") +
       tm_polygons(col = "white") +
       tm_text(text = "name", size = 2) +
    tm_shape(ALGA.sf) +
       tm_polygons(col = "gray") +
    tm_shape(TLH_site.sf) +
       tm_symbols(shape = 21) +
       tm_text(text = "name") + 
    tm_compass(type = "arrow", position = c("right", "top")) +
    tm_scale_bar(position = c("right", "top"), size = .75) +
    tm_style("natural") )

library(grid)
main.tm
print(inset.tm, vp = viewport(.3, .3, width = .7, height = .4))
```

Get the data. Ordered online from 
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail

TALLAHASSEE REGIONAL AIRPORT, FL US (Station ID: GHCND:USW00093805)
TALLAHASSEE, FL US (Station ID: GHCND:USC00088754)

Do the same for Sofia Bulgaria
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:BUM00015614/detail

https://docs.opendata.aws/noaa-ghcn-pds/readme.html

Global Historical Climate Network includes daily land surface observations from around the world. The GHCN-Daily was developed to meet the needs of climate analysis and monitoring studies that require data at a sub-monthly time resolution (e.g., assessments of the frequency of heavy rainfall, heat wave duration, etc.). The dataset includes observations from World Meteorological Organization, Cooperative, and CoCoRaHS networks. If observed, the station dataset includes max and minimum temperatures, total precipitation, snowfall, and depth of snow on ground. Some U.S. station data are typically delayed only 24 hours. 

### Analysis of temperatures when data are available at both sites.
```{r}
df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) 

duplicateRows <- duplicated(df$Date)
duplicateDates <- df$Date[duplicateRows]

df1 <- df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USC00088754")

df2 <- df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USW00093805") %>%
  select(STATION2 = STATION, TMAX2 = TMAX, TMIN2 = TMIN, PRCP2 = PRCP)

dfOverlap <- cbind(df1, df2)
```

```{r}
dfOverlap <- dfOverlap %>%
  mutate(OLDwarmer = TMAX - TMAX2 > 0,
         OLDcolder = TMAX - TMAX2 < 0)

sum(dfOverlap$OLDwarmer[dfOverlap$TMIN >= 78], na.rm = TRUE)
sum(dfOverlap$OLDcolder[dfOverlap$TMIN >= 78], na.rm = TRUE)

mean(dfOverlap$TMAX, na.rm = TRUE)
mean(dfOverlap$TMAX2, na.rm = TRUE)

mean(dfOverlap$TMIN, na.rm = TRUE)
mean(dfOverlap$TMIN2, na.rm = TRUE)

mean(dfOverlap$TMAX[dfOverlap$TMAX >= 95], na.rm = TRUE)
mean(dfOverlap$TMAX2[dfOverlap$TMAX >= 95], na.rm = TRUE)

mean(dfOverlap$TMAX[dfOverlap$TMAX >= 100], na.rm = TRUE)
mean(dfOverlap$TMAX2[dfOverlap$TMAX >= 100], na.rm = TRUE)

```
The overall daily high temperature means are nearly identical. For hot days the difference in average highs is in favor of downtown.

Daily temperatures in Tallahassee were recorded from a station downtown until the early 1940s. Since then at the airport. Avg difference in highs during the overlap period is small (less than 1/2°F). But it is much more likely to get to 100°F+ downtown. 

Cumulative logistic regression model. Note: The model cannot predict temperatures above 100 at the airport since there were none in the record during the overlapping years. It can assign an exceedance probability for a larger range of input temperatures.
```{r}
library(brms)

minTMAX2 <- min(dfModel2$TMAX2)

dfModel2 <- dfModel %>%
  filter(TMAX >= 94) %>%
  mutate(TI = TMAX2 - minTMAX2 + 1,
         TDT = scale(TMAX))

family <- brms::cumulative(threshold = "equidistant")
formula <- TI ~ 1

get_prior(formula, data = dfModel2, family = family)

fit0 <- brm(formula = formula,
           data = dfModel2,
           family = family,
           prior = set_prior("student_t(3, 0, 10)", class = "Intercept"),
           seed = 9121)
fixef(fit0)

fit0_out <- predict(fit0, probs = c(0, 1))
head(fit0_out)

formula <- TI ~ TMAX

get_prior(formula, data = dfModel2, family = family)

fit1 <- brm(formula = formula,
            data = dfModel2,
            family = family,
            prior = c(set_prior("normal(0, 1)", class = "b"),
                     set_prior("student_t(7, 0, 10)", class = "Intercept")),
           seed = 78121)

summary(fit1)

library(tidybayes)
library(modelr)

# initialize out data frame
out <- dfModel2 %>%
  data_grid(TMAX = 96:106) %>%
  add_predicted_draws(fit1, n = 1000) %>%
  mutate(pTMAX2 = as.integer(.prediction)  + minTMAX2 - 1) %>%
  group_by(TMAX) %>%
  summarize(nTMAX = n(),
            prob100 = sum(pTMAX2 >= 100)/nTMAX) 

out

# rbind to the initialized data frame
for(i in 2:100){
  out <- dfModel2 %>%
  data_grid(TMAX = 96:106) %>%
  add_predicted_draws(fit1, n = 1000) %>%
  mutate(pTMAX2 = as.integer(.prediction)  + minTMAX2 - 1) %>%
  group_by(TMAX) %>%
  summarize(nTMAX = n(),
            prob100 = sum(pTMAX2 >= 100)/nTMAX) %>%
    rbind(out)
}

out$I <- rep(1:100, each = 11)

library(ggridges)

ggplot(out, aes(x = TMAX, y = prob100, group = I)) +
  geom_point(alpha = .2, size = .5) +
  scale_x_continuous(breaks = 96:106) +
  xlab("High Temperature Downtown Tallahassee (°F)") +
  ylab("Posterior Probability") +
  ggtitle("Chance the TLH Airport Reports a 100+°F Day",
          subtitle = "Given specific high temperatures downtown") +
  theme_minimal() +
  theme(panel.grid.minor.x = element_blank())
```

Read only the data from the downtown site. Filter by days at or above 96F then use the model to predict the temperature at the airport. August 31, 1895 TMAX = 2768 is removed.
```{r}
DTN.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USC00088754') %>%
      filter(TMAX >= 96) %>%
      filter(TMAX != 2768) %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP) 
table(DTN.df$TMAX)
```

Predictions. What is the likely number of 100 degree days at the airport over the period of record when the daily high temperature was recorded downtown?
```{r}
n100 <- numeric()
for(i in 1:100){
TMAX2 <- add_predicted_draws(newdata = data.frame(TMAX = DTN.df$TMAX, Date = DTN.df$Date), 
                    fit1, n = 1000) %>%
  mutate(TMAX2est = as.integer(.prediction) + minTMAX2 - 1) %>%
  group_by(Date) %>%
  sample_n(size = 1) %>%
  pull(TMAX2est) 
n100 <- c(n100, sum(TMAX2 >= 100))
}
```

Predictions. No loop. Look at a single realization. Join predictions data frame with the original downtown data frame.
```{r}
TMAX2.df <- add_predicted_draws(newdata = data.frame(TMAX = DTN.df$TMAX, Date = DTN.df$Date), 
                    fit1, n = 1000) %>%
  mutate(TMAX2est = as.integer(.prediction) + minTMAX2 - 1) %>%
  group_by(Date) %>%
  sample_n(size = 2) %>%
  select(Date, TMAX2est)

x <- add_predicted_draws(newdata = data.frame(TMAX = DTN.df$TMAX, Date = DTN.df$Date), 
                    fit1, n = 1000) %>%
  mutate(TMAX2est = as.integer(.prediction) + minTMAX2 - 1) %>%
  group_by(Date) %>%
  sample_n(size = 3) %>%
  pull(TMAX2est)

z <- data.frame(matrix(x, ncol = 3, byrow = FALSE))
names(z) <- c("Corrected 1", "Corrected 2", "Corrected 3")
z$Date <- DTN.df$Date

YearCount.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USC00088754') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP) %>%
left_join(x, by = "Date") %>%
  filter(Date < as.Date("1940-03-01")) %>%
  group_by(Year) %>%
  
# Needs work
  summarize(Corrected = sum(TMAX2est >= 100, na.rm = TRUE),
            Uncorrected = sum(TMAX >= 100, na.rm = TRUE))
  
```

Read only the data from the airport site.
```{r}
TLH.df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP)
```

```{r}
YearCount2.df <- TLH.df %>%
  group_by(Year) %>%
  summarize(Corrected = sum(TMAX >= 100, na.rm = TRUE),
            Uncorrected = Corrected)

library(reshape2)
YC.df <- rbind(YearCount.df, YearCount2.df) %>%
  melt(id.vars = "Year")

ggplot(YC.df, aes(x = Year, y = value, fill = value)) + 
  geom_bar(stat='identity') + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  geom_text(aes(label = value), vjust = -.5, size = 3) +
  ylab("Number of Days") +
  facet_wrap(~ variable, nrow = 2) +
  ggtitle(label = expression(paste('Number of days at or above 100', {}^o, " F")),
          subtitle = "Tallahassee, Florida, USA (1892-2018)") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 11), 
        legend.position = "none") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50"))

```
* TMAX: Daily maximum temperature, 
* TMIN: Daily minimum temperature, 
* PRCP: Daily total precipitation, 
* WDF1: Wind direction of fastest one-minute wind, 
* WSF1: Wind speed of fastest one-minute wind

Check for missing values in maximum and minimum temperature
```{r}
sum(is.na(TLH.df$TMAX))
TLH.df$Date[is.na(TLH.df$TMAX)]
TLH.df$Date[is.na(TLH.df$TMIN)]
```

Add temperatures for July 8, 2005 from Weather Underground.
```{r}
TLH.df$TMAX[TLH.df$Date == "2005-07-08"] <- 96
TLH.df$TMIN[TLH.df$Date == "2005-07-08"] <- 71
```

Line plot of the average annual daily high (low) temperature.
https://cedricscherer.netlify.com/2019/05/17/the-evolution-of-a-ggplot-ep.-1/
```{r}
library(ggplot2)

df %>% 
  filter(Year >= 1941, TMAX >= 93) %>%
  group_by(Year) %>%
  summarize(avgT = mean(TMAX, na.rm = TRUE)) %>%
#  summarize(avgP = mean(PRCP, na.rm = TRUE)) %>%
ggplot(aes(x = Year, y = avgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab(expression(paste('Temperature (', {}^o, " F)"))) +
  ggtitle(label = "Annual Average Daily High Temperature",
          subtitle = "Tallahassee, Florida, USA (1941-2018)") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) +
  theme_bw()
```

Bar plot of the number of 100+ degree days.
```{r}
df %>% 
  group_by(Year) %>%
  summarize(N100 = sum(TMAX >= 100, na.rm = TRUE)) %>%
ggplot(aes(x = Year, y = N100, fill = N100)) + 
  geom_bar(stat='identity') + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  geom_text(aes(label = N100), vjust = -.5, size = 3) +
  ylab("Number of Days") +
  ggtitle(label = expression(paste('Number of days at or above 100', {}^o, " F")),
          subtitle = "Tallahassee, Florida, USA (1940-2018)") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 11), 
        legend.position = "none") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) 
```

Last hot days?
```{r}
df %>% 
  filter(TMAX >= 100 & Month == 5) %>%
  arrange(desc(Date)) %>%
  head(n = 20)

df %>%
  arrange(desc(TMAX)) %>%
  head()
```

Hot days since 2009.
```{r}
hotDates <- df %>%
  filter(Year >= 2009 & TMAX >= 100) %>%
  select(Date) %>%
  pull()
```

Hourly data.
```{r}
dfH <- read.csv(file = "TLH_Hourly2009.csv", 
                header = TRUE,
                stringsAsFactors = FALSE)
str(dfH)
```

Report type: https://www1.ncdc.noaa.gov/pub/data/ish/ish-format-document.pdf

FM-12 = SYNOP Report of surface observation form a fixed land station
FM-15 = METAR Aviation routine weather report
FM-16 = SPECI Aviation selected special weather report

Convert the date/time character string to a data/time obect.
```{r}
library(lubridate)

dfH2 <- dfH %>%
  mutate(DateTime = ymd_hms(DATE, tz = "EST"),
         Date = as.Date(DateTime, tz = "EST"),
         TempF = as.integer(HourlyDryBulbTemperature),
         ReportType = REPORT_TYPE) %>%
  select(ReportType, DateTime, Date, TempF) %>%
  filter(Date %in% hotDates) %>%
  filter(ReportType == 'FM-15')
```

Consecutive hours at or above 100F.
```{r}
hotTimes <- rle(dfH2$TempF >= 100)
consecHours <- hotTimes$lengths[hotTimes$values]
consecHours <- consecHours[!is.na(consecHours)]

dfH2 <- dfH2 %>%
  filter(TempF >= 100) %>%
  mutate(dateNo = rep(1:length(consecHours), consecHours))
```

Join the daily data with the hourly data.
```{r}
df2 <- df %>%
  select(Date, TMAX) %>%
  filter(TMAX >= 100)

dfH2 <- left_join(dfH2, df2)
```

Round the times to nearest hour.
```{r}
dfH2 <- dfH2 %>%
  mutate(Hour =  hour(round(DateTime, "hours")))
```