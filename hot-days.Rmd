---
title: "Hot Days in Tallahassee"
author: "James Elsner and Svetoslava Elsner"
date: "5/16/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

### Lede: The hots are getting hotter

Here we look at the statistics of extremely hot days in Tallahassee, Florida. An extremely hot day is defined as one in which the maximum temperature exceeds 100$+^\circ$ F.  A record of daily maximum temperatures from the regional airport reveals an increasing trend in the occurrence of such days since the 1970s. The trend results from an increase in the occurrence of hot events and an increase in the average length of an event. We speculate that the trend is related to changes in the intensity and location of deep layer ridging, perhaps exacerbated by changes in land use and global warming.

Deep layer ridging

loss of daytime heating

About the climate in Tallahassee.
http://weatherspark.com/history/31772/2013/Tallahassee-Florida-United-States

Need a map with inset. See file:///Users/jameselsner/Desktop/ClassNotes/appl-spat-stat/09-Lesson.html

```{r}
library(dplyr)
library(lubridate)
```

Weather station site location 30.39306°, -84.35333°.
```{r}
TLH_site.df <- data.frame(name = "TLH            ", 
                          lon = -84.35333, 
                          lat = 30.39306)
TLH_site.sf <- st_as_sf(TLH_site.df, 
                        coords = c("lon", "lat"))
st_crs(TLH_site.sf) <- 4326
```
```{r}
library(tmap)
library(spData)

FL1.sf <- us_states %>%
  filter(NAME == "Florida")

( inset.tm <- tm_shape(world) +
  tm_polygons() +
tm_shape(world[world$name_long == "United States", ]) +
  tm_polygons(col = "gray") +
tm_shape(us_states, projection = "laea_NA", is.master = TRUE) + 
  tm_borders() +
  tm_compass(type = "arrow", position = c("left", "bottom")) +
  tm_scale_bar(position = c("left", "bottom"), size = .75) +
  tm_style("natural") +
tm_shape(FL1.sf) +
  tm_polygons(col = "white") )

library(USAboundaries)

FL.sf <- us_states(states = "Florida")
FL.sf$name <- "            Florida"
ALGA.sf <- us_states(states = c("Alabama", "Georgia"))

( main.tm <- 
    tm_shape(FL.sf, projection = "laea_NA") +
       tm_polygons(col = "white") +
       tm_text(text = "name", size = 2) +
    tm_shape(ALGA.sf) +
       tm_polygons(col = "gray") +
    tm_shape(TLH_site.sf) +
       tm_symbols(shape = 21) +
       tm_text(text = "name") + 
    tm_compass(type = "arrow", position = c("right", "top")) +
    tm_scale_bar(position = c("right", "top"), size = .75) +
    tm_style("natural") )

library(grid)
main.tm
print(inset.tm, vp = viewport(.3, .3, width = .7, height = .4))
```

Get the data. 

Ordered online from 
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail

TALLAHASSEE REGIONAL AIRPORT, FL US (Station ID: GHCND:USW00093805)

Older data from
TALLAHASSEE, FL US (Station ID: GHCND:USC00088754)


Do the same for Sofia Bulgaria
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:BUM00015614/detail

https://docs.opendata.aws/noaa-ghcn-pds/readme.html

Global Historical Climate Network includes daily land surface observations from around the world. The GHCN-Daily was developed to meet the needs of climate analysis and monitoring studies that require data at a sub-monthly time resolution (e.g., assessments of the frequency of heavy rainfall, heat wave duration, etc.). The dataset includes observations from World Meteorological Organization, Cooperative, and CoCoRaHS networks. If observed, the station dataset includes max and minimum temperatures, total precipitation, snowfall, and depth of snow on ground. Some U.S. station data are typically delayed only 24 hours. 

Removed second header record and added header names to match columns.
```{r}
df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
      arrange(factor(STATION, levels = c("USC00088754", "USW00093805"))) %>%
      mutate(Date = as.Date(DATE)) %>%
      select(STATION, Date, TMAX, TMIN, PRCP)
```

Analysis of temperatures when data are available at both sites.
```{r}
duplicateRows <- duplicated(df$Date)
duplicateDates <- df$Date[duplicateRows]

df1 <- df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USC00088754")

df2 <- df %>%
  filter(Date %in% duplicateDates) %>%
  filter(STATION == "USW00093805") %>%
  select(STATION2 = STATION, TMAX2 = TMAX, TMIN2 = TMIN, PRCP2 = PRCP)

dfOverlap <- cbind(df1, df2)
```

```{r}
dfOverlap <- dfOverlap %>%
  mutate(OLDwarmer = TMAX - TMAX2 > 0,
         OLDcolder = TMAX - TMAX2 < 0)

sum(dfOverlap$OLDwarmer[dfOverlap$TMIN >= 78], na.rm = TRUE)
sum(dfOverlap$OLDcolder[dfOverlap$TMIN >= 78], na.rm = TRUE)

mean(dfOverlap$TMAX, na.rm = TRUE)
mean(dfOverlap$TMAX2, na.rm = TRUE)
mean(dfOverlap$TMIN, na.rm = TRUE)
mean(dfOverlap$TMIN2, na.rm = TRUE)
```

Read only the data from the current site.
```{r}
df <- read.csv(file = 'TLH_SOD1892.csv',
               stringsAsFactors = FALSE,
               header = TRUE) %>%
#      filter(STATION == 'USW00093805') %>%
      filter(STATION == 'USC00088754') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
      select(Date, Year, Month, Day, TMAX, TMIN, PRCP)
```

* TMAX: Daily maximum temperature, 
* TMIN: Daily minimum temperature, 
* PRCP: Daily total precipitation, 
* WDF1: Wind direction of fastest one-minute wind, 
* WSF1: Wind speed of fastest one-minute wind

Check for missing values in maximum and minimum temperature
```{r}
sum(is.na(df$TMAX))
df$Date[is.na(df$TMAX)]
df$Date[is.na(df$TMIN)]
```

Add temperatures for July 8, 2005 from Weather Underground.
```{r}
df$TMAX[df$Date == "2005-07-08"] <- 96
df$TMIN[df$Date == "2005-07-08"] <- 71
```

Line plot of the average annual daily high (low) temperature.
https://cedricscherer.netlify.com/2019/05/17/the-evolution-of-a-ggplot-ep.-1/
```{r}
library(ggplot2)

df %>% 
  filter(Year >= 1941, TMAX >= 93) %>%
  group_by(Year) %>%
  summarize(avgT = mean(TMAX, na.rm = TRUE)) %>%
#  summarize(avgP = mean(PRCP, na.rm = TRUE)) %>%
ggplot(aes(x = Year, y = avgT)) +
  geom_point(size = 3) +
  geom_line() +
  ylab(expression(paste('Temperature (', {}^o, " F)"))) +
  ggtitle(label = "Annual Average Daily High Temperature",
          subtitle = "Tallahassee, Florida, USA (1941-2018)") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) +
  theme_bw()
```

Bar plot of the number of 100+ degree days.
```{r}
df %>% 
  group_by(Year) %>%
  summarize(N100 = sum(TMAX >= 100, na.rm = TRUE)) %>%
ggplot(aes(x = Year, y = N100, fill = N100)) + 
  geom_bar(stat='identity') + 
  scale_fill_continuous(low = 'orange', high = 'red') +
  geom_text(aes(label = N100), vjust = -.5, size = 3) +
  ylab("Number of Days") +
  ggtitle(label = expression(paste('Number of days at or above 100', {}^o, " F")),
          subtitle = "Tallahassee, Florida, USA (1940-2018)") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 11), 
        legend.position = "none") +
  labs(caption = "Data: Global Historical Climate Network") +
  theme(plot.caption = element_text(size = 9, color = "grey50")) 
```

Last hot days?
```{r}
df %>% 
  filter(TMAX >= 100 & Month == 5) %>%
  arrange(desc(Date)) %>%
  head(n = 20)

df %>%
  arrange(desc(TMAX)) %>%
  head()
```

Hot days since 2009.
```{r}
hotDates <- df %>%
  filter(Year >= 2009 & TMAX >= 100) %>%
  select(Date) %>%
  pull()
```

Hourly data.
```{r}
dfH <- read.csv(file = "TLH_Hourly2009.csv", 
                header = TRUE,
                stringsAsFactors = FALSE)
str(dfH)
```

Report type: https://www1.ncdc.noaa.gov/pub/data/ish/ish-format-document.pdf

FM-12 = SYNOP Report of surface observation form a fixed land station
FM-15 = METAR Aviation routine weather report
FM-16 = SPECI Aviation selected special weather report

Convert the date/time character string to a data/time obect.
```{r}
library(lubridate)

dfH2 <- dfH %>%
  mutate(DateTime = ymd_hms(DATE, tz = "EST"),
         Date = as.Date(DateTime, tz = "EST"),
         TempF = as.integer(HourlyDryBulbTemperature),
         ReportType = REPORT_TYPE) %>%
  select(ReportType, DateTime, Date, TempF) %>%
  filter(Date %in% hotDates) %>%
  filter(ReportType == 'FM-15')
```

Consecutive hours at or above 100F.
```{r}
hotTimes <- rle(dfH2$TempF >= 100)
consecHours <- hotTimes$lengths[hotTimes$values]
consecHours <- consecHours[!is.na(consecHours)]

dfH2 <- dfH2 %>%
  filter(TempF >= 100) %>%
  mutate(dateNo = rep(1:length(consecHours), consecHours))
```

Join the daily data with the hourly data.
```{r}
df2 <- df %>%
  select(Date, TMAX) %>%
  filter(TMAX >= 100)

dfH2 <- left_join(dfH2, df2)
```

Round the times to nearest hour.
```{r}
dfH2 <- dfH2 %>%
  mutate(Hour =  hour(round(DateTime, "hours")))
```